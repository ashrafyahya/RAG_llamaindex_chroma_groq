{"docstore/metadata": {"e1add8a2-a049-4087-be31-0fecbbeb46b8": {"doc_hash": "1ca7a37e15771416819806f0dc8fb38d00dd52f6351d0ef8e86af0c0968ecc35"}, "09306511-9368-45dd-bd23-d78f49943584": {"doc_hash": "9ab360f00ed6d6e9d1d16f5aefc830a13504686eb1583898317866b36017e740"}, "cc2c6307-50b4-4f9e-a238-eee9a11fec60": {"doc_hash": "6a90f88aefd518b0315839e75690edff4aa881e4a36724dda8e0422dbb033169"}, "8ec27990-c945-43b7-8d1c-c795c80cff05": {"doc_hash": "4c8a8733e78c1898c1f87a92dca7e04d2a1a2a2c6c2a3ff81b088f6b49cfdcd7"}, "0fd9c97d-f996-47cd-8c25-c43ef24e3e64": {"doc_hash": "06b24f218fb531c0d10bdfbd4c44adb25ca1020a924c1ef9f4af2154d8d3a665"}, "fb112cbc-fb3e-434b-b18f-4de586538f07": {"doc_hash": "b0d4f9cb9de4814c82f3266e23f1ee756de10e38ebb341b0ab8b8afb2420631e"}, "00097974-57d0-4e06-a239-b8601266e61e": {"doc_hash": "e539c0c533cb75f6efd6b4bb52054ebd9ab85036e82017a42438f6ed50ad18fb"}, "4b01a43b-900a-4ed5-a8c2-8f2cf7855774": {"doc_hash": "0184118fd8791e352d36f36873338e5075410aefa08d4f2c0ca78e69c34e5ffa"}, "a1bcb7bc-0fa3-4607-bceb-f3b9d4b04d6a": {"doc_hash": "c5295094b61f271ef4ca837740d39fa074d1db4bba895ab5d96494fb6da53018"}, "9dfb3cb6-21c4-49b3-aa4e-e67375e4f18c": {"doc_hash": "0807d547fe7a2a585d6ad71ebae4ca8559947b92c68a8fd667bd0914a4510d80"}, "f51aec7a-4a05-4c40-b591-05a71bf21752": {"doc_hash": "21d72a6cfec5e5cc02c77a5eae8c2fc8ca153f1715f38e24bb479d80629978c4"}, "c93fdbf5-72a8-4db2-bdf5-59b9728e3943": {"doc_hash": "1afdbab8eab7c05e4dfb67918177d63377ca3f0ddd63943dc567c1f632b48eaa"}, "9b2ad89f-0928-4a23-8a60-e111849f108e": {"doc_hash": "7a9f86ff01ed41a5f4b0ffe857eea9797dc6954dc6b39bda0776d1579b00faf0"}, "b0bcce73-f841-4e88-9a59-516a5ea589d6": {"doc_hash": "6934ca1aa5d744520247c0bbfd47d950365a75761df1f15bdb93c4f8ed0a2e35"}, "0df1bdd0-68e6-4577-a03d-63ee31918d8f": {"doc_hash": "42c2a5e705fe9de8a1470cc70ec07301243a4ad318110a8131c33387c51d93bc"}, "df5a9a5e-98bd-4ad8-a6dc-efbb94c67134": {"doc_hash": "8bf7d1a52da1122a6defec40939375f6e4ab3ddf10d17f27027a7df14653f96d"}, "8efa28c5-8856-4ff4-b3c4-bccb795d3ea8": {"doc_hash": "82a7f05d7d23e0217c551972a7b1c85d0d5003a6a3faa7c6d6b7af6d387b41a8"}, "42556d54-3e79-43cb-a9c8-39509465a212": {"doc_hash": "f62c9038b91d3c0b0733f842597cf42f7ed76eb0676c4e1e2395a94487bff0ee"}, "2e179271-37d9-438b-ba9c-46a0bea68be6": {"doc_hash": "7000b3f6883579e8312de77beb535185a594c519c0425c50373e93a9b1c9764e"}, "7c80e127-bdd6-44a4-b766-15103b9415b8": {"doc_hash": "ffb8a57376935644b4d9bb3c0255a76662db71a2a8f2858475073d4ab7b22b0c", "ref_doc_id": "e1add8a2-a049-4087-be31-0fecbbeb46b8"}, "4b9b8128-b7fa-404b-ac76-d477e2e6437a": {"doc_hash": "bc48b37e8446b4f82eff4d378de01fed0f6bce691515df9a352769353a9b0abf", "ref_doc_id": "e1add8a2-a049-4087-be31-0fecbbeb46b8"}, "05bd2eb6-57b5-404f-b000-4e65d6a9d433": {"doc_hash": "0fbec3d700f42589d10373925bd99ce37e468d3029e9ef73b0c7a9ca4e134d20", "ref_doc_id": "09306511-9368-45dd-bd23-d78f49943584"}, "745d7c13-2791-44a2-b8ef-563f0421186b": {"doc_hash": "a07470cf2796e6cda894fe0a1507934c354ed983c232acf2c32af434d6411990", "ref_doc_id": "09306511-9368-45dd-bd23-d78f49943584"}, "938b0991-fda5-4acf-85f4-43480f562a7a": {"doc_hash": "d84e6c8b6ed0cf70c5b61cde531224a899fd6753b0d0f87bd31607dc693e590a", "ref_doc_id": "09306511-9368-45dd-bd23-d78f49943584"}, "07dde401-8e89-4548-8cf3-91626408a678": {"doc_hash": "22884d3cf10e6506da15fd0414d3457aa49735c3245f84175a62803cea00672d", "ref_doc_id": "cc2c6307-50b4-4f9e-a238-eee9a11fec60"}, "5ee15464-5976-4166-8435-8083a65cf11c": {"doc_hash": "cf0ce2f3baed2fbfb69885a6b8a58de8c6694b74faf7d85855836a0fc9588948", "ref_doc_id": "cc2c6307-50b4-4f9e-a238-eee9a11fec60"}, "e25aaa75-32f3-4abd-b222-285e941ce5de": {"doc_hash": "e2bf240e27476a1e33d7606314ca7d8bb9ec647fd38e52f1160f5c31e9724c6b", "ref_doc_id": "8ec27990-c945-43b7-8d1c-c795c80cff05"}, "23c2adf7-89dc-4bc0-90df-7f6d82843a32": {"doc_hash": "c99691e968aab5a4344ec4ccee9f9f82d8b6ee17e1359972676f8f77b9a13d8c", "ref_doc_id": "8ec27990-c945-43b7-8d1c-c795c80cff05"}, "dd12ef72-2585-4ba1-b178-e1c00ee96099": {"doc_hash": "7123065b33c3bb51431ab41cea65f1e4f72da377ffc0a50ceca24da75020a839", "ref_doc_id": "8ec27990-c945-43b7-8d1c-c795c80cff05"}, "6118470a-d587-461b-8949-6f3f9ea27d1f": {"doc_hash": "49f182e9985d98fbdef6fb0cc10f358e144a097a952d98e794e7f4793712387f", "ref_doc_id": "8ec27990-c945-43b7-8d1c-c795c80cff05"}, "995492b5-9409-48fa-a905-76a7f0204636": {"doc_hash": "6b4b660f2587c75fa519f6619f6a108036ebeb71b2dee290a948e697d99e4217", "ref_doc_id": "0fd9c97d-f996-47cd-8c25-c43ef24e3e64"}, "d965779b-6e75-4bb2-b4da-4ca3dbbb5ffa": {"doc_hash": "7823a952e6f46342261db2fdfbf4600f6366d2cf0e5186b7937763aa7bbd55d8", "ref_doc_id": "0fd9c97d-f996-47cd-8c25-c43ef24e3e64"}, "22d00a69-eba9-4b86-93d3-74e943663b99": {"doc_hash": "fcd5d4db402f381a6dfafbcbb9806d8160ebf98a1a69b64ab380d56c737841a2", "ref_doc_id": "0fd9c97d-f996-47cd-8c25-c43ef24e3e64"}, "fb9f2f20-e97e-4a38-ae31-b502186bec3e": {"doc_hash": "bdfa4b048912e0bfa2590427719ea54efaba4b5eda8ceaff6414785ef5f3d666", "ref_doc_id": "fb112cbc-fb3e-434b-b18f-4de586538f07"}, "64a347e2-310b-4572-b336-a28109d2b3a6": {"doc_hash": "cbf08e4fb885926cd8a09ac3b1d91b29bd84786adc35b698d8beb26deae263f5", "ref_doc_id": "fb112cbc-fb3e-434b-b18f-4de586538f07"}, "a4050874-9262-4feb-9555-1612005a72fc": {"doc_hash": "1638180ab69b9ba2b9d018b96b07b1f5334eece36d087171265ae63e97fa3235", "ref_doc_id": "fb112cbc-fb3e-434b-b18f-4de586538f07"}, "a0e59385-b271-43e1-93ab-710fa55b89c0": {"doc_hash": "57071ae4a13b60d31190e3e7438ea89fbc58096349cf99be976fbaacbe86e4ff", "ref_doc_id": "fb112cbc-fb3e-434b-b18f-4de586538f07"}, "c4cb4d88-8397-432a-add8-cb059b8e3df0": {"doc_hash": "505856e2d06dba5523a1a888abdb5940cfc44ba461e5f854891f423ca9819759", "ref_doc_id": "00097974-57d0-4e06-a239-b8601266e61e"}, "7a8858a5-2b39-4506-b45e-86ea0540975d": {"doc_hash": "2bcc921e0a5a99fbf208e655c06d7fab1fb0af2566311fcec528281078dc77ea", "ref_doc_id": "00097974-57d0-4e06-a239-b8601266e61e"}, "7cf68e7c-a833-4fb9-a1e1-5e036ea996d9": {"doc_hash": "87c83e4dfa40719e36444b8c35aae53e1305345b6098483f52f6bacf18fe5527", "ref_doc_id": "00097974-57d0-4e06-a239-b8601266e61e"}, "a5f2c965-526a-44df-8a6b-f7c259a59b2b": {"doc_hash": "2e2871ba17e5f3cf4365c5a53a5c66f7fe0b30cb4dd57073a765c53b786d71d8", "ref_doc_id": "4b01a43b-900a-4ed5-a8c2-8f2cf7855774"}, "0f6d7a31-7aff-4384-b20f-8e4273d5229e": {"doc_hash": "166b0652db89247c8ef97e96134e3cb75acad2ee3e2d911804bed18ae81c82a9", "ref_doc_id": "4b01a43b-900a-4ed5-a8c2-8f2cf7855774"}, "c4052aeb-504f-49f8-8de4-5dc39c3e3885": {"doc_hash": "12acfe47931cffedacf49b6fa1eb386c6578d5446d83f25b1478b515064220e8", "ref_doc_id": "a1bcb7bc-0fa3-4607-bceb-f3b9d4b04d6a"}, "6b7266c9-60c1-46e3-bc5c-0b551781c4a0": {"doc_hash": "d6685096136770148c5643fa1b680020ea98000e5f4e46a662468712494eb33f", "ref_doc_id": "a1bcb7bc-0fa3-4607-bceb-f3b9d4b04d6a"}, "3ecc03b9-3a7c-43f3-ab6a-491069e6ba3f": {"doc_hash": "abbe7db0b3e85cddb2965876875edfa0b4f6888bdcb5f381d68f0d6d18d03bb9", "ref_doc_id": "9dfb3cb6-21c4-49b3-aa4e-e67375e4f18c"}, "26d9c2e9-ddb6-4de0-9ba9-148f271d2b4f": {"doc_hash": "3792883a01297fb807cf78997c0b42aaa2d5f1b42694f5854ab43a80b03556e7", "ref_doc_id": "9dfb3cb6-21c4-49b3-aa4e-e67375e4f18c"}, "b1494240-d797-48b9-b378-feb1b581643e": {"doc_hash": "cfff1b4bb7038a42ea5d172969b02c5336d9deb4d4a5dbf78fdc7cc2c4b03058", "ref_doc_id": "f51aec7a-4a05-4c40-b591-05a71bf21752"}, "98e50929-ed42-4f2f-8c6c-183a78de460e": {"doc_hash": "fd6b152a99a01b010613721306a5ed7d4c86e9842f635aa843a67a03daf01dfb", "ref_doc_id": "f51aec7a-4a05-4c40-b591-05a71bf21752"}, "036fb84a-77b9-407b-97f8-982265dd1d0b": {"doc_hash": "9a98784d067082ca020625fbd15e7ea8e900fe455fef49ffc86159152901c49d", "ref_doc_id": "c93fdbf5-72a8-4db2-bdf5-59b9728e3943"}, "57d8286c-3d2e-4a38-aa54-24794706f2d6": {"doc_hash": "769b3aa633b5a5e2875f4be998cc4477b89e206f8a21d0a308763ba7afe1c619", "ref_doc_id": "c93fdbf5-72a8-4db2-bdf5-59b9728e3943"}, "697258ed-63ec-4c56-a781-bde066f61770": {"doc_hash": "4fffe034b20e22c088f4543fe170cd1312988004dbac37e513851f33ec40374f", "ref_doc_id": "c93fdbf5-72a8-4db2-bdf5-59b9728e3943"}, "fbe8f11d-5489-4577-b6c2-67194362d73b": {"doc_hash": "b069d7ee18662cc1f580b4cbb9640dc569390bde38861542c8be9e2ec11dc0c5", "ref_doc_id": "9b2ad89f-0928-4a23-8a60-e111849f108e"}, "c930e63c-d36a-4518-9cae-7fb8a47fcca4": {"doc_hash": "8d230e7200d30d3e3a09b12774b468fedd3b863b7c9b89f73f4535c6a04961d7", "ref_doc_id": "9b2ad89f-0928-4a23-8a60-e111849f108e"}, "731cc7ac-33a7-405e-b34b-5e062dd00380": {"doc_hash": "49d6a74b43e702d9a504f20d17f7b7ea7d9b800db7eb0abecedb4e6219606385", "ref_doc_id": "9b2ad89f-0928-4a23-8a60-e111849f108e"}, "792a6d39-5865-4c66-82f9-fa1a7d7897a3": {"doc_hash": "9872e3f0b91e106eb89993d101036348822ffed043855284451a5a2e1d811d7b", "ref_doc_id": "b0bcce73-f841-4e88-9a59-516a5ea589d6"}, "4d7b0a81-3b06-421f-976b-38e70ec89f54": {"doc_hash": "cd04a48a8ee8aa4fe853daca4f492e19a5cf81be0fbfad28bdce925336a9b8de", "ref_doc_id": "b0bcce73-f841-4e88-9a59-516a5ea589d6"}, "ddb7110c-6c6f-4360-8d6a-cf1f06daaa6f": {"doc_hash": "265a1bdbb26a6a2fedb446b3de3361aa5ecb028cf6731d5901c2b53822b88dd3", "ref_doc_id": "b0bcce73-f841-4e88-9a59-516a5ea589d6"}, "1017ef55-40f7-46f8-92e2-037e3a2e42a3": {"doc_hash": "c41c8716ddd8b074fc775752954e42aca5e5d22dfd6fae1d6a4f89ff9c254b1e", "ref_doc_id": "0df1bdd0-68e6-4577-a03d-63ee31918d8f"}, "6954397d-11d4-4da9-89f4-df89d08e8219": {"doc_hash": "81f32154dc9682d60c319e359a16636eb501e866723404640b8611ddabede4e5", "ref_doc_id": "0df1bdd0-68e6-4577-a03d-63ee31918d8f"}, "67a434d8-9e8f-4d23-b274-2438dbbfea46": {"doc_hash": "f43f60af8d0b93f650e62dc3929adc951f1afaa734c5db9f74ba5f1ce5ba3737", "ref_doc_id": "df5a9a5e-98bd-4ad8-a6dc-efbb94c67134"}, "1cd3ea53-af63-4fcf-8861-9b9018c9627f": {"doc_hash": "173ae09958f2c5f97825b85b1feb4d87676cca3602f7677415053f9df61b0b83", "ref_doc_id": "df5a9a5e-98bd-4ad8-a6dc-efbb94c67134"}, "de5066a9-0a84-4bfa-be2a-d7f2abe6076a": {"doc_hash": "498391091f10a11ce8b744489217f992c675631ff2c512c0c17045ac4dc3b418", "ref_doc_id": "8efa28c5-8856-4ff4-b3c4-bccb795d3ea8"}, "e21033d1-92da-49e4-b2e1-cb6ac6ba4823": {"doc_hash": "c350ca7a4e64d0a18fce88390b542ef1043e80ad96bc9d7c81834fe36a3f4e69", "ref_doc_id": "8efa28c5-8856-4ff4-b3c4-bccb795d3ea8"}, "aa51c1ef-9695-4ad4-ae7a-7a309764a755": {"doc_hash": "4acbf16c44680d8f8c977ab1d72272cdf0bdd15506c51d3a512575b8d424b163", "ref_doc_id": "42556d54-3e79-43cb-a9c8-39509465a212"}, "463a9b72-bce4-4882-8360-855f3df9c411": {"doc_hash": "6ab5210da65f514354ac6f10ddfe78e0fd737b2bf220aca24ae5b1899ddb302c", "ref_doc_id": "42556d54-3e79-43cb-a9c8-39509465a212"}, "285dda77-e923-417a-8f0e-3e73d59a00b7": {"doc_hash": "dba9a1a3ca54e1222587e40c58d0501c2f933e9995860291075a100453fe57c7", "ref_doc_id": "2e179271-37d9-438b-ba9c-46a0bea68be6"}, "84fe8f8e-b99e-429c-a218-0bc21a11a166": {"doc_hash": "e942b3d5ce23ef54d3dbc0afe51f4552b0e9c50c800e4aeb9ea666f5eaa672e4", "ref_doc_id": "2e179271-37d9-438b-ba9c-46a0bea68be6"}}, "docstore/ref_doc_info": {"e1add8a2-a049-4087-be31-0fecbbeb46b8": {"node_ids": ["7c80e127-bdd6-44a4-b766-15103b9415b8", "4b9b8128-b7fa-404b-ac76-d477e2e6437a"], "metadata": {"file_name": "Agentic AI_ Agents vs. Workflows Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Agents vs. Workflows Summary.docx", "file_size": 8350, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "09306511-9368-45dd-bd23-d78f49943584": {"node_ids": ["05bd2eb6-57b5-404f-b000-4e65d6a9d433", "745d7c13-2791-44a2-b8ef-563f0421186b", "938b0991-fda5-4acf-85f4-43480f562a7a"], "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "cc2c6307-50b4-4f9e-a238-eee9a11fec60": {"node_ids": ["07dde401-8e89-4548-8cf3-91626408a678", "5ee15464-5976-4166-8435-8083a65cf11c"], "metadata": {"file_name": "Building Prompts for Agentic AI Systems Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Prompts for Agentic AI Systems Summary.docx", "file_size": 8470, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "8ec27990-c945-43b7-8d1c-c795c80cff05": {"node_ids": ["e25aaa75-32f3-4abd-b222-285e941ce5de", "23c2adf7-89dc-4bc0-90df-7f6d82843a32", "dd12ef72-2585-4ba1-b178-e1c00ee96099", "6118470a-d587-461b-8949-6f3f9ea27d1f"], "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}}, "0fd9c97d-f996-47cd-8c25-c43ef24e3e64": {"node_ids": ["995492b5-9409-48fa-a905-76a7f0204636", "d965779b-6e75-4bb2-b4da-4ca3dbbb5ffa", "22d00a69-eba9-4b86-93d3-74e943663b99"], "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "fb112cbc-fb3e-434b-b18f-4de586538f07": {"node_ids": ["fb9f2f20-e97e-4a38-ae31-b502186bec3e", "64a347e2-310b-4572-b336-a28109d2b3a6", "a4050874-9262-4feb-9555-1612005a72fc", "a0e59385-b271-43e1-93ab-710fa55b89c0"], "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "00097974-57d0-4e06-a239-b8601266e61e": {"node_ids": ["c4cb4d88-8397-432a-add8-cb059b8e3df0", "7a8858a5-2b39-4506-b45e-86ea0540975d", "7cf68e7c-a833-4fb9-a1e1-5e036ea996d9"], "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}}, "4b01a43b-900a-4ed5-a8c2-8f2cf7855774": {"node_ids": ["a5f2c965-526a-44df-8a6b-f7c259a59b2b", "0f6d7a31-7aff-4384-b20f-8e4273d5229e"], "metadata": {"file_name": "LLM_Function_Chaining_Guide_Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\LLM_Function_Chaining_Guide_Summary.docx", "file_size": 8791, "creation_date": "2025-11-09", "last_modified_date": "2025-11-01"}}, "a1bcb7bc-0fa3-4607-bceb-f3b9d4b04d6a": {"node_ids": ["c4052aeb-504f-49f8-8de4-5dc39c3e3885", "6b7266c9-60c1-46e3-bc5c-0b551781c4a0"], "metadata": {"file_name": "Memory Management Strategies for Long AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies for Long AI Conversations.docx", "file_size": 8508, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}}, "9dfb3cb6-21c4-49b3-aa4e-e67375e4f18c": {"node_ids": ["3ecc03b9-3a7c-43f3-ab6a-491069e6ba3f", "26d9c2e9-ddb6-4de0-9ba9-148f271d2b4f"], "metadata": {"file_name": "Memory Management Strategies in AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies in AI Conversations.docx", "file_size": 8375, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}}, "f51aec7a-4a05-4c40-b591-05a71bf21752": {"node_ids": ["b1494240-d797-48b9-b378-feb1b581643e", "98e50929-ed42-4f2f-8c6c-183a78de460e"], "metadata": {"file_name": "Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_size": 8822, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}}, "c93fdbf5-72a8-4db2-bdf5-59b9728e3943": {"node_ids": ["036fb84a-77b9-407b-97f8-982265dd1d0b", "57d8286c-3d2e-4a38-aa54-24794706f2d6", "697258ed-63ec-4c56-a781-bde066f61770"], "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "9b2ad89f-0928-4a23-8a60-e111849f108e": {"node_ids": ["fbe8f11d-5489-4577-b6c2-67194362d73b", "c930e63c-d36a-4518-9cae-7fb8a47fcca4", "731cc7ac-33a7-405e-b34b-5e062dd00380"], "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}}, "b0bcce73-f841-4e88-9a59-516a5ea589d6": {"node_ids": ["792a6d39-5865-4c66-82f9-fa1a7d7897a3", "4d7b0a81-3b06-421f-976b-38e70ec89f54", "ddb7110c-6c6f-4360-8d6a-cf1f06daaa6f"], "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "0df1bdd0-68e6-4577-a03d-63ee31918d8f": {"node_ids": ["1017ef55-40f7-46f8-92e2-037e3a2e42a3", "6954397d-11d4-4da9-89f4-df89d08e8219"], "metadata": {"file_name": "System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_size": 8553, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}}, "df5a9a5e-98bd-4ad8-a6dc-efbb94c67134": {"node_ids": ["67a434d8-9e8f-4d23-b274-2438dbbfea46", "1cd3ea53-af63-4fcf-8861-9b9018c9627f"], "metadata": {"file_name": "The Core Components of AI Agents Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\The Core Components of AI Agents Summary.docx", "file_size": 8668, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}, "8efa28c5-8856-4ff4-b3c4-bccb795d3ea8": {"node_ids": ["de5066a9-0a84-4bfa-be2a-d7f2abe6076a", "e21033d1-92da-49e4-b2e1-cb6ac6ba4823"], "metadata": {"file_name": "Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_size": 8224, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}}, "42556d54-3e79-43cb-a9c8-39509465a212": {"node_ids": ["aa51c1ef-9695-4ad4-ae7a-7a309764a755", "463a9b72-bce4-4882-8360-855f3df9c411"], "metadata": {"file_name": "Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_size": 8950, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}}, "2e179271-37d9-438b-ba9c-46a0bea68be6": {"node_ids": ["285dda77-e923-417a-8f0e-3e73d59a00b7", "84fe8f8e-b99e-429c-a218-0bc21a11a166"], "metadata": {"file_name": "What is Agentic AI Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\What is Agentic AI Summary.docx", "file_size": 8878, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}}}, "docstore/data": {"7c80e127-bdd6-44a4-b766-15103b9415b8": {"__data__": {"id_": "7c80e127-bdd6-44a4-b766-15103b9415b8", "embedding": null, "metadata": {"file_name": "Agentic AI_ Agents vs. Workflows Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Agents vs. Workflows Summary.docx", "file_size": 8350, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e1add8a2-a049-4087-be31-0fecbbeb46b8", "node_type": "4", "metadata": {"file_name": "Agentic AI_ Agents vs. Workflows Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Agents vs. Workflows Summary.docx", "file_size": 8350, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "1ca7a37e15771416819806f0dc8fb38d00dd52f6351d0ef8e86af0c0968ecc35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4b9b8128-b7fa-404b-ac76-d477e2e6437a", "node_type": "1", "metadata": {}, "hash": "92438ce03640b25a671b446b92f89424ea45bf0f6f2d6d80db62d54f8fc586c1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Agentic AI: Agents vs. Workflows (AAIDC-Week1-Lesson-5)\n\n\n\nThis article clarifies the distinction between agents and workflows in Agentic AI, addressing a common point of confusion in the AI field. It emphasizes that not every Large Language Model (LLM) call constitutes an \"agent.\"\n\n\n\nNot Every LLM Call is an Agent\n\n\n\nWorkflows\n\n Workflows are defined as systems where LLMs and tools are orchestrated through predefined code paths. The process flow is predetermined by the developer.\n\n\n\nAgents\n\n Agents are systems where LLMs dynamically direct their own processes and tool usage. They maintain control over how they accomplish tasks and possess autonomy in decision-making.\n\n Analogy: A workflow is like a director instructing actors precisely, while an agent system provides a mission, and the agent decides how to achieve it.\n\n\n\nDo You Really Need an Agent?\n\n Before developing complex agentic systems, it's crucial to assess if an agent is truly necessary for the task. Successful implementations often utilize simple, composable patterns rather than overly complex frameworks.\n\n Practical Decision Steps:\n\n   1.  Start with the simplest solution possible, often optimizing single LLM calls with retrieval and in-context examples.\n\n   2.  Increase complexity only when demonstrably needed, considering the trade-off between latency, cost, and improved task performance.\n\n   3.  Consider the nature of your task:\n\n       If it is well-defined with predictable steps, a workflow might be more suitable.\n\n       If it requires flexibility and model-driven decision-making, an agent might be better.\n\n\n\nWhen True Agents Make Sense\n\n True agents excel in open-ended problems where:\n\n   The required number of steps is difficult to predict.\n\n   A fixed path cannot be hardcoded.\n\n   The LLM operates for multiple turns, requiring a degree of trust in its decision-making.\n\n Real-world examples include:\n\n   Solving complex coding tasks that involve modifying many files based on a task description.\n\n   Customer support interactions that require both conversation and actions with external systems.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2098, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4b9b8128-b7fa-404b-ac76-d477e2e6437a": {"__data__": {"id_": "4b9b8128-b7fa-404b-ac76-d477e2e6437a", "embedding": null, "metadata": {"file_name": "Agentic AI_ Agents vs. Workflows Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Agents vs. Workflows Summary.docx", "file_size": 8350, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e1add8a2-a049-4087-be31-0fecbbeb46b8", "node_type": "4", "metadata": {"file_name": "Agentic AI_ Agents vs. Workflows Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Agents vs. Workflows Summary.docx", "file_size": 8350, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "1ca7a37e15771416819806f0dc8fb38d00dd52f6351d0ef8e86af0c0968ecc35", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c80e127-bdd6-44a4-b766-15103b9415b8", "node_type": "1", "metadata": {"file_name": "Agentic AI_ Agents vs. Workflows Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Agents vs. Workflows Summary.docx", "file_size": 8350, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "ffb8a57376935644b4d9bb3c0255a76662db71a2a8f2858475073d4ab7b22b0c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The Bottom Line\n\n Success in the LLM space is about building the right system for specific needs, not necessarily the most sophisticated one.\n\n Core Principles:\n\n   1.  Maintain simplicity in your design.\n\n   2.  Prioritize transparency by explicitly showing planning steps.\n\n   3.  Carefully craft your interfaces through thorough documentation and testing.\n\n It is important to ask whether a use case truly requires the flexibility and autonomy of an agent or if a well-designed workflow would be more effective. The course will cover building both workflows and agents.\n\n\n\nNote:\n\nFor more detailed information on building effective agents and understanding the distinction between agents and workflows, refer to Anthropic's research article: Building effective agents.\n\nA Week 1 assignment is available in the Files section to help reinforce the concepts learned.\n\n\n\nOriginal Link: https://app.readytensor.ai/publications/Xq3L2HSWLPou", "mimetype": "text/plain", "start_char_idx": 2102, "end_char_idx": 3039, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "05bd2eb6-57b5-404f-b000-4e65d6a9d433": {"__data__": {"id_": "05bd2eb6-57b5-404f-b000-4e65d6a9d433", "embedding": null, "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09306511-9368-45dd-bd23-d78f49943584", "node_type": "4", "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "9ab360f00ed6d6e9d1d16f5aefc830a13504686eb1583898317866b36017e740", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "745d7c13-2791-44a2-b8ef-563f0421186b", "node_type": "1", "metadata": {}, "hash": "d110dda1d9d66d1bec2aae75775b9a5ce7a60cb5b640d30a7a7f41ea39f3042e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Agentic AI: Tools of the Trade Summary\n\n\n\nTools and Frameworks\n\nThe field of Agentic AI offers various tools and frameworks for building agents, catering to both developers and non-coders.\n\n\n\nCode-Based Frameworks\n\nFor developers requiring granular control over workflows, memory, and multi-agent collaboration:\n\n\n\n1.  LangGraph\n\n    Developed by the LangChain team, LangGraph allows designing AI workflows as visual graphs. It's ideal for multi-step processes that require agents to remember their current task status, such as customer support systems with escalation and follow-up.\n\n    Docs: https://langchain-ai.github.io/langgraph/\n\n    GitHub: https://github.com/langchain-ai/langgraph\n\n\n\n2.  Microsoft AutoGen\n\n    AutoGen facilitates collaborative AI systems where agents can write, review, and test code. They can debate, self-correct, and utilize external tools, making it suitable for coding teams and research.\n\n    Docs: https://microsoft.github.io/autogen/stable/\n\n    GitHub: https://github.com/microsoft/autogen\n\n\n\n3.  CrewAI\n\n    CrewAI organizes agents into specialized roles, enabling a collaborative workflow. For instance, a \"Researcher\" gathers data, a \"Writer\" drafts a report, and an \"Editor\" refines it, passing tasks efficiently without micromanagement.\n\n    Docs: https://docs.crewai.com/introduction\n\n    GitHub: https://github.com/crewAIInc/crewAI\n\n\n\n4.  LlamaIndex\n\n    (Formerly GPT Index) LlamaIndex serves as a data librarian for AI agents, helping them fetch and connect data from diverse sources like PDFs, SQL databases, and APIs to ensure informed and accurate responses.\n\n    Docs: https://docs.llamaindex.ai/en/stable/\n\n    GitHub: https://github.com/run-llama/llama_index\n\n\n\n5.  Pydantic AI\n\n    This framework simplifies structured output for agents, built by the creators of Pydantic. It's noted for its ease of use in agent construction.\n\n    Docs: https://ai.pydantic.dev/\n\n    GitHub: https://github.com/pydantic/pydantic-ai", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1976, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "745d7c13-2791-44a2-b8ef-563f0421186b": {"__data__": {"id_": "745d7c13-2791-44a2-b8ef-563f0421186b", "embedding": null, "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09306511-9368-45dd-bd23-d78f49943584", "node_type": "4", "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "9ab360f00ed6d6e9d1d16f5aefc830a13504686eb1583898317866b36017e740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "05bd2eb6-57b5-404f-b000-4e65d6a9d433", "node_type": "1", "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "0fbec3d700f42589d10373925bd99ce37e468d3029e9ef73b0c7a9ca4e134d20", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "938b0991-fda5-4acf-85f4-43480f562a7a", "node_type": "1", "metadata": {}, "hash": "92899d007775fce9884f854752f5ea89617ca687113b949138a326ba4b9a5175", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "6.  OpenAI Swarm\n\n    An experimental framework from OpenAI, Swarm explores collaborative problem-solving using lightweight AI agents (one for data gathering, one for analysis, one for action). It's not yet production-ready.\n\n    GitHub: https://github.com/openai/swarm\n\n\n\nVisual (GUI) Frameworks\n\nFor users who prefer visual interfaces and no-code solutions:\n\n\n\n1.  Rivet\n\n    Rivet offers a drag-and-drop interface, akin to digital LEGO, for building AI agents. It allows connecting AI models to CRMs and adding actions like \"send email\" for automation without coding.\n\n    Website: https://rivet.ironcladapp.com/\n\n\n\n2.  Vellum\n\n    Vellum is a tool for prompt engineers, enabling side-by-side testing of multiple prompt versions to identify and deploy the most effective ones via a clean interface, similar to A/B testing for AI workflows.\n\n    Website: https://www.vellum.ai/\n\n\n\n3.  Langflow\n\n    A drag-and-drop alternative to LangChain, Langflow allows users to visually construct AI workflows, such as linking a \"web search\" node to a \"summarize\" node, to create concise summaries from multiple articles.\n\n    Website: https://www.langflow.org/\n\n\n\n4.  Flowise AI\n\n    An open-source counterpart to Langflow, Flowise AI enables building chatbots by linking data sources (e.g., company handbooks) to LLMs via a drag-and-drop interface, requiring no coding.\n\n    Website: https://flowiseai.com/\n\n\n\n5.  Chatbase\n\n    Chatbase lets you train a ChatGPT-like assistant on your own data. It supports uploading documents like FAQ PDFs, customizing design, and embedding the assistant on websites for 24/7 customer service.\n\n    Website: https://www.chatbase.co/\n\n\n\nFactors for choosing a Framework\n\nWhen selecting an Agentic AI framework, consider the following:", "mimetype": "text/plain", "start_char_idx": 1980, "end_char_idx": 3740, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "938b0991-fda5-4acf-85f4-43480f562a7a": {"__data__": {"id_": "938b0991-fda5-4acf-85f4-43480f562a7a", "embedding": null, "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09306511-9368-45dd-bd23-d78f49943584", "node_type": "4", "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "9ab360f00ed6d6e9d1d16f5aefc830a13504686eb1583898317866b36017e740", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "745d7c13-2791-44a2-b8ef-563f0421186b", "node_type": "1", "metadata": {"file_name": "Agentic AI_ Tools of the Trade Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Agentic AI_ Tools of the Trade Summary.docx", "file_size": 9338, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "a07470cf2796e6cda894fe0a1507934c354ed983c232acf2c32af434d6411990", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Factors for choosing a Framework\n\nWhen selecting an Agentic AI framework, consider the following:\n\n\n\n1.  Use Case: The primary purpose of your agent will dictate which framework is most suitable.\n\n2.  Level of Abstraction: Decide whether you need fine-grained control over prompts, memory, and workflows or prefer a higher-level framework.\n\n3.  Criticality: For mission-critical systems, opt for robust, battle-tested tools.\n\n4.  Team Skills: Choose tools that align with your team's expertise (e.g., Python experts vs. no-code users).\n\n5.  Time/Budget: Evaluate if a quick solution is needed or if resources allow for a more customized approach.\n\n6.  Integration Requirements: Consider if the agent needs to connect with external systems (e.g., Slack, Jira).\n\n7.  Scalability Considerations: Plan for monitoring, logging, and auto-scaling if the system will serve many users.\n\n\n\nA Perspective on Picking the Right Framework\n\nA video provides insights into framework selection for Agentic AI projects. It highlights that personal projects prioritize speed and flexibility, while enterprise decisions demand maturity, support, and long-term viability, illustrating with industry and startup examples.\n\n\n\nOriginal Link: https://app.readytensor.ai/publications/hjbeURATH5ul", "mimetype": "text/plain", "start_char_idx": 3643, "end_char_idx": 4913, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "07dde401-8e89-4548-8cf3-91626408a678": {"__data__": {"id_": "07dde401-8e89-4548-8cf3-91626408a678", "embedding": null, "metadata": {"file_name": "Building Prompts for Agentic AI Systems Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Prompts for Agentic AI Systems Summary.docx", "file_size": 8470, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cc2c6307-50b4-4f9e-a238-eee9a11fec60", "node_type": "4", "metadata": {"file_name": "Building Prompts for Agentic AI Systems Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Prompts for Agentic AI Systems Summary.docx", "file_size": 8470, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "6a90f88aefd518b0315839e75690edff4aa881e4a36724dda8e0422dbb033169", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5ee15464-5976-4166-8435-8083a65cf11c", "node_type": "1", "metadata": {}, "hash": "781d1f4b28d9aab100e17a16270c7a68b327e9bd205b54c74b64766645b953db", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Building Prompts for Agentic AI Systems (AAIDC-Week2-Lesson-1a) - Summary\n\n\n\nThis lesson focuses on designing effective prompts for Agentic AI systems by using a structured, modular approach. It emphasizes moving beyond casual prompting to create explicit, repeatable, and goal-aligned instructions for AI. This method allows for configurable and reliable prompt design, leading to trustworthy and controllable AI behavior.\n\n\n\nThe Anatomy of a Prompt\n\n\n\nPrompts are composed of modular components that can be mixed and matched.\n\n\n\nCore Components (Usually Required):\n\n  Instruction: Defines the task for the AI.\n\n  Input: The data or content the AI needs to work with.\n\n\n\nOptional Components (Often Game-Changing):\n\n  Context: Background information that influences the response.\n\n  Output format: Specifies the desired structure of the result.\n\n  Role/persona: Dictates how the AI should \"act\" (e.g., an expert, a casual explainer).\n\n  Output constraints: Limits on length, style, or content.\n\n  Tone/style: Guides the voice and approach the AI should use.\n\n  Examples: Provides samples of desired output.\n\n  Goal: States the underlying objective or purpose of the AI's response.\n\n\n\nThese components collectively form a prompt template, enabling fine-tuning of results by adjusting individual elements rather than rewriting the entire prompt.\n\n\n\nPrompt Development Walkthrough: One Task, Many Improvements\n\n\n\nThe lesson demonstrates prompt improvement through a summarization task, using a technical article as input.\n\n\n\n1.  Baseline (Instruction + Input Only):\n\n    Initial attempts with only instruction and input often produce lengthy and formal summaries (e.g., over 250 words with bullet points).\n\n\n\n2.  Adding Output Constraints:\n\n    Specifying format and length (e.g., \"a single paragraph of 80-100 words\") leads to more concise and targeted outputs.\n\n\n\n3.  Adding a Role/Persona:\n\n    Defining the AI's role (e.g., \"a helpful AI assistant explaining to a general audience\") makes the language more accessible and less academic.\n\n\n\n4.  Adding Style and Tone Guidelines:\n\n    Including specific instructions on writing style (e.g., \"clear, concise, natural, engaging, avoiding jargon\") refines the voice, making it sound less \"AI-generated\" and ensuring consistency.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2274, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5ee15464-5976-4166-8435-8083a65cf11c": {"__data__": {"id_": "5ee15464-5976-4166-8435-8083a65cf11c", "embedding": null, "metadata": {"file_name": "Building Prompts for Agentic AI Systems Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Prompts for Agentic AI Systems Summary.docx", "file_size": 8470, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cc2c6307-50b4-4f9e-a238-eee9a11fec60", "node_type": "4", "metadata": {"file_name": "Building Prompts for Agentic AI Systems Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Prompts for Agentic AI Systems Summary.docx", "file_size": 8470, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "6a90f88aefd518b0315839e75690edff4aa881e4a36724dda8e0422dbb033169", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "07dde401-8e89-4548-8cf3-91626408a678", "node_type": "1", "metadata": {"file_name": "Building Prompts for Agentic AI Systems Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Prompts for Agentic AI Systems Summary.docx", "file_size": 8470, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "22884d3cf10e6506da15fd0414d3457aa49735c3245f84175a62803cea00672d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5.  Adding a Clear Goal:\n\n    Explicitly stating the purpose of the summary (e.g., \"help the reader decide if they should read the full article\") guides the AI in prioritizing and presenting information, often resulting in direct recommendations.\n\n\n\nThe Power of Prompt Modularization\n\n\n\nThis modular approach provides granular control over each aspect of the AI's behavior, making prompts configurable and reusable. Instead of creating one-off prompts, developers can build a scalable system or a \"prompt design library\" by combining different components to suit varying tasks, audiences, or contexts.\n\n\n\nConclusion\n\n\n\nBy systematically adding instruction, constraints, role, style guidelines, and goals, a basic prompt can be transformed into a sophisticated, multi-component system. This method ensures precise control over Agentic AI behavior and enables dynamic configuration of AI logic, which will be further explored in future lessons.\n\n\n\nOriginal Publication: https://app.readytensor.ai/publications/36Hu3DC3TLdu", "mimetype": "text/plain", "start_char_idx": 2278, "end_char_idx": 3299, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e25aaa75-32f3-4abd-b222-285e941ce5de": {"__data__": {"id_": "e25aaa75-32f3-4abd-b222-285e941ce5de", "embedding": null, "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8ec27990-c945-43b7-8d1c-c795c80cff05", "node_type": "4", "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "4c8a8733e78c1898c1f87a92dca7e04d2a1a2a2c6c2a3ff81b088f6b49cfdcd7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "23c2adf7-89dc-4bc0-90df-7f6d82843a32", "node_type": "1", "metadata": {}, "hash": "9bd4087bc3fb3414f0f6b34fa3e708953384bfb1dd05a3690b7ced7e5242aab1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Building Your Research Assistant: A Step-by-Step RAG Implementation (AAIDC-Week3-Lesson-4)\n\n\n\nIntroduction:\n\nThis lesson focuses on enabling AI assistants to access and retrieve external, up-to-date knowledge in real-time, transforming them from general conversationalists into knowledgeable experts. The process involves building a complete Retrieval Augmented Generation (RAG) pipeline using real research publications. The lesson includes a two-part video walkthrough for implementation.\n\n\n\nThe Knowledge Limitation Problem:\n\nTraditional AI assistants are limited to the knowledge they acquired during their training cutoff. This means they cannot provide current information or company-specific policies. To address this, AI assistants need real-time access to external knowledge.\n\n\n\nBuilding a Research Assistant: A Hands-On Journey\n\n\n\nStep 1: Setting Up the Knowledge Base\n\nThe first step involves initializing a persistent ChromaDB vector database with cosine similarity for efficient retrieval of related research content.\n\nCode:\n\nimport chromadb\n\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\nfrom langchain_huggingface import HuggingFaceEmbeddings\n\n\n\nclient = chromadb.PersistentClient(path=\"./research_db\")\n\ncollection = client.get_or_create_collection(\n\n    name=\"ml_publications\",\n\n    metadata={\"hnsw:space\": \"cosine\"}\n\n)\n\nembeddings = HuggingFaceEmbeddings(\n\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n\n)\n\n\n\nStep 2: Loading the Publications\n\nPublications from .txt files are loaded using LangChain's TextLoader, and their content is extracted as strings, preparing them for the next stage.\n\nCode:\n\nimport os\n\nfrom langchain_community.document_loaders import TextLoader\n\n\n\ndef load_research_publications(documents_path):\n\n    documents = []\n\n    for file in os.listdir(documents_path):\n\n        if file.endswith(\".txt\"):\n\n            file_path = os.path.join(documents_path, file)\n\n            try:\n\n                loader = TextLoader(file_path)\n\n                loaded_docs = loader.load()\n\n                documents.extend(loaded_docs)\n\n            except Exception as e:\n\n                print(f\"Error loading {file}: {str(e)}\")\n\n    publications = []\n\n    for doc in documents:\n\n        publications.append(doc.page_content)\n\n    return publications", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2304, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "23c2adf7-89dc-4bc0-90df-7f6d82843a32": {"__data__": {"id_": "23c2adf7-89dc-4bc0-90df-7f6d82843a32", "embedding": null, "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8ec27990-c945-43b7-8d1c-c795c80cff05", "node_type": "4", "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "4c8a8733e78c1898c1f87a92dca7e04d2a1a2a2c6c2a3ff81b088f6b49cfdcd7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e25aaa75-32f3-4abd-b222-285e941ce5de", "node_type": "1", "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "e2bf240e27476a1e33d7606314ca7d8bb9ec647fd38e52f1160f5c31e9724c6b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "dd12ef72-2585-4ba1-b178-e1c00ee96099", "node_type": "1", "metadata": {}, "hash": "f60f6e8c4be57c06f0917200be1dc79c9114e2205b3b9a695e0b988d8128c86b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Step 3: Chunking Our Publications\n\nPublications are broken down into smaller, searchable chunks to improve retrieval efficiency and focus on specific topics.\n\nCode:\n\ndef chunk_research_paper(paper_content, title):\n\n    text_splitter = RecursiveCharacterTextSplitter(\n\n        chunk_size=1000,\n\n        chunk_overlap=200,\n\n        separators=[\"\n\n\n\n\", \"\n\n\", \". \", \" \", \"\"]\n\n    )\n\n    chunks = text_splitter.split_text(paper_content)\n\n    chunk_data = []\n\n    for i, chunk in enumerate(chunks):\n\n        chunk_data.append({\n\n            \"content\": chunk,\n\n            \"title\": title,\n\n            \"chunk_id\": f\"{title}_{i}\",\n\n        })\n\n    return chunk_data\n\n\n\nStep 4: Creating Embeddings\n\nText chunks are converted into 384-dimensional vector embeddings using a HuggingFace model, capturing their semantic meaning to allow for similarity-based searches.\n\nCode:\n\nimport torch\n\nfrom langchain_huggingface import HuggingFaceEmbeddings\n\n\n\ndef embed_documents(documents: list[str]) -> list[list[float]]:\n\n    device = (\n\n        \"cuda\"\n\n        if torch.cuda.is_available()\n\n        else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n\n    )\n\n    model = HuggingFaceEmbeddings(\n\n        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n\n        model_kwargs={\"device\": device},\n\n    )\n\n    embeddings = model.embed_documents(documents)\n\n    return embeddings\n\n\n\nStep 5: Storing in Vector Database\n\nChunks and their corresponding embeddings are stored in ChromaDB, which indexes them for fast retrieval based on similarity.\n\nCode:\n\ndef insert_publications(collection: chromadb.Collection, publications: list[str]):\n\n    next_id = collection.count()\n\n    for publication in publications:\n\n        chunked_publication = chunk_publication(publication)\n\n        embeddings = embed_documents(chunked_publication)\n\n        ids = list(range(next_id, next_id + len(chunked_publication)))\n\n        ids = [f\"document_{id}\" for id in ids]\n\n        collection.add(\n\n            embeddings=embeddings,\n\n            ids=ids,\n\n            documents=chunked_publication,\n\n        )\n\n        next_id += len(chunked_publication)", "mimetype": "text/plain", "start_char_idx": 2308, "end_char_idx": 4424, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dd12ef72-2585-4ba1-b178-e1c00ee96099": {"__data__": {"id_": "dd12ef72-2585-4ba1-b178-e1c00ee96099", "embedding": null, "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8ec27990-c945-43b7-8d1c-c795c80cff05", "node_type": "4", "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "4c8a8733e78c1898c1f87a92dca7e04d2a1a2a2c6c2a3ff81b088f6b49cfdcd7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "23c2adf7-89dc-4bc0-90df-7f6d82843a32", "node_type": "1", "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "c99691e968aab5a4344ec4ccee9f9f82d8b6ee17e1359972676f8f77b9a13d8c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6118470a-d587-461b-8949-6f3f9ea27d1f", "node_type": "1", "metadata": {}, "hash": "ceefcd26d1fd7596211652ff0420ee50a46c430140a0fea50edcabb35ed5f674", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Step 6: Intelligent Retrieval\n\nWhen a user queries the system, the most relevant content chunks are retrieved from the ChromaDB using vector similarity search.\n\nCode:\n\ndef search_research_db(query, collection, embeddings, top_k=5):\n\n    query_vector = embeddings.embed_query(query)\n\n    results = collection.query(\n\n        query_embeddings=[query_vector],\n\n        n_results=top_k,\n\n        include=[\"documents\", \"metadatas\", \"distances\"]\n\n    )\n\n    relevant_chunks = []\n\n    for i, doc in enumerate(results[\"documents\"][0]):\n\n        relevant_chunks.append({\n\n            \"content\": doc,\n\n            \"title\": results[\"metadatas\"][0][i][\"title\"],\n\n            \"similarity\": 1 - results[\"distances\"][0][i]\n\n        })\n\n    return relevant_chunks\n\n\n\nStep 7: Generating Research-Backed Answers\n\nRetrieved knowledge is combined with a Large Language Model (LLM) using a prompt template to generate precise, source-backed answers.\n\nCode:\n\nfrom langchain_groq import ChatGroq\n\nfrom langchain.prompts import PromptTemplate\n\n\n\ndef answer_research_question(query, collection, embeddings, llm):\n\n    relevant_chunks = search_research_db(query, collection, embeddings, top_k=3)\n\n    context = \"\n\n\n\n\".join([\n\n        f\"From {chunk['title']}:\n\n{chunk['content']}\" \n\n        for chunk in relevant_chunks\n\n    ])\n\n    prompt_template = PromptTemplate(\n\n        input_variables=[\"context\", \"question\"],\n\n        template=\"\"\"\n\nBased on the following research findings, answer the researcher's question:\n\n\n\nResearch Context:\n\n{context}\n\n\n\nResearcher's Question: {question}\n\n\n\nAnswer: Provide a comprehensive answer based on the research findings above.\n\n\"\"\"\n\n    )\n\n    prompt = prompt_template.format(context=context, question=query)\n\n    response = llm.invoke(prompt)\n\n    return response.content, relevant_chunks\n\n\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n\nanswer, sources = answer_research_question(\n\n    \"What are effective techniques for handling class imbalance?\",\n\n    collection, \n\n    embeddings, \n\n    llm\n\n)", "mimetype": "text/plain", "start_char_idx": 4428, "end_char_idx": 6431, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6118470a-d587-461b-8949-6f3f9ea27d1f": {"__data__": {"id_": "6118470a-d587-461b-8949-6f3f9ea27d1f", "embedding": null, "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8ec27990-c945-43b7-8d1c-c795c80cff05", "node_type": "4", "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "4c8a8733e78c1898c1f87a92dca7e04d2a1a2a2c6c2a3ff81b088f6b49cfdcd7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dd12ef72-2585-4ba1-b178-e1c00ee96099", "node_type": "1", "metadata": {"file_name": "Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Building Your Research Assistant_ A Step-by-Step RAG Implementation.docx", "file_size": 10615, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "7123065b33c3bb51431ab41cea65f1e4f72da377ffc0a50ceca24da75020a839", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Result:\n\nBefore RAG, AI would give generic answers. After RAG, the AI provides specific, source-backed answers, referencing research within its database (e.g., \"Decision Threshold Calibration emerged as the most consistently effective technique...\").\n\n\n\nKey Takeaways:\n\nRAG transforms generic AI into domain experts.\n\nThe RAG pipeline is straightforward: chunk documents -> create embeddings -> store in vector DB -> retrieve + generate.\n\nCode implementation is accessible using libraries like ChromaDB and LangChain.\n\nIt provides precise, source-backed answers.\n\nThe system can be made production-ready with error handling, performance monitoring, and multi-format support.\n\n\n\nVideo Walkthroughs:\n\nThe lesson includes two video walkthroughs:\n\nPart 1: Building Your Vector Database (0TuESd2ZwPs)\n\nPart 2: Retrieval and Answer Generation (nnSSLrbxgQE)\n\n\n\nWebsite Link: https://app.readytensor.ai/publications/IBOMURRgN8Dn", "mimetype": "text/plain", "start_char_idx": 6435, "end_char_idx": 7355, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "995492b5-9409-48fa-a905-76a7f0204636": {"__data__": {"id_": "995492b5-9409-48fa-a905-76a7f0204636", "embedding": null, "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0fd9c97d-f996-47cd-8c25-c43ef24e3e64", "node_type": "4", "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "06b24f218fb531c0d10bdfbd4c44adb25ca1020a924c1ef9f4af2154d8d3a665", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d965779b-6e75-4bb2-b4da-4ca3dbbb5ffa", "node_type": "1", "metadata": {}, "hash": "0ad50ef6f51d84f3467419c6792c20aa75467351a21a2832866291b52c4912ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Here is a summary of the provided article on \"From Text to Data: Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2)\"\n\n\n\nTL;DR\n\n\n\nThis lesson introduces two primary methods for generating structured output from Large Language Models (LLMs): prompt-based formatting and model-native structured output. Prompt-based formatting utilizes clear instructions and examples, making it compatible with any LLM, while model-native structured output enforces format and type safety directly during generation, supported by advanced LLMs like OpenAI\u2019s GPT-4. The article highlights the importance of tools such as Pydantic and LangChain in validating outputs and recommends model-native output for building reliable, production-ready LLM applications.\n\n\n\nWhy Structured Outputs Matter?\n\n\n\nLLMs are excellent at generating free-form text, but integrating these responses into applications that require structured, machine-readable data (e.g., product names, prices, features, categories) can be challenging. Reliably extracting specific information from free-flowing language is difficult and prone to errors. Structured output transforms LLM responses from expressive text into dependable data, facilitating easier chaining of outputs into functions, feeding results into APIs, or storing them in databases. This lesson focuses on designing prompts, using validation tools, and leveraging model-native features to ensure LLMs produce structured data.\n\n\n\nCreating Structured Output\n\n\n\nThere are two main approaches to generating structured data from an LLM:\n\n\n\n1.  Regular Prompting with Format Hints:\n\n    This method involves guiding the LLM with carefully designed instructions and examples. It is widely compatible with most LLMs and relies on strong prompting strategies and post-processing tools like parsers and validators.\n\n\n\n    Key Techniques for Effective Structured Prompts:\n\n    *   Explicit Format Instructions: Clearly define the desired structure (e.g., JSON, XML).\n\n    *   Demonstrate with an Example: Provide a well-formatted sample for the model to imitate.\n\n    *   Be Precise and Predictable: Avoid vague language and stick to a strict template.\n\n    *   Standardize Field Names and Types: Maintain consistent formatting to reduce output variability.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2258, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d965779b-6e75-4bb2-b4da-4ca3dbbb5ffa": {"__data__": {"id_": "d965779b-6e75-4bb2-b4da-4ca3dbbb5ffa", "embedding": null, "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0fd9c97d-f996-47cd-8c25-c43ef24e3e64", "node_type": "4", "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "06b24f218fb531c0d10bdfbd4c44adb25ca1020a924c1ef9f4af2154d8d3a665", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "995492b5-9409-48fa-a905-76a7f0204636", "node_type": "1", "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "6b4b660f2587c75fa519f6619f6a108036ebeb71b2dee290a948e697d99e4217", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "22d00a69-eba9-4b86-93d3-74e943663b99", "node_type": "1", "metadata": {}, "hash": "68e33da87692c313f7c3d5d9e059f3ea831a5e0d7d60e7f360f29bce9aabdb6a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Example: Prompting for JSON Output (Python example provided in the original article)\n\n    This approach, while effective, still carries the risk of the model occasionally deviating from the expected format, necessitating post-processing and error handling.\n\n\n\n2.  Model-Native Structured Output:\n\n    This advanced approach integrates structure enforcement directly into the model's generation process. You define the schema (e.g., with a Pydantic model), and the LLM generates output that adheres to this schema at the decoding level, guaranteeing structure. This eliminates the need for complex parsing or error handling after generation.\n\n\n\n    This method is supported by specific advanced LLMs, such as OpenAI\u2019s GPT-4 and Anthropic\u2019s Claude. Tools like LangChain simplify accessing this capability, particularly with `.with_structured_output(...)`.\n\n\n\n    Example: Native Structured Output with LangChain (Python example with Pydantic model and `gpt-4o-mini` provided in the original article)\n\n    This results in clean, structured, and type-safe data without ambiguity or extensive prompt engineering.\n\n\n\n    Why This Is a Game-Changer:\n\n    *   Guaranteed Format Compliance: The model is forced to follow the defined schema, preventing unexpected field generation.\n\n    *   Minimal Error Handling: Structure is enforced during generation, reducing the need for post-validation.\n\n    *   Better Developer Experience: Working directly with typed objects (like Pydantic models) is more robust than parsing strings.\n\n    *   Fewer Surprises: Eliminates unexpected formats or missing fields in critical applications.\n\n\n\nCoding Example\n\n\n\nThe article refers to three videos that demonstrate these concepts in action:\n\n*   Free-Form Output (No Structure): Shows inconsistencies when no structure is enforced.\n\n*   Prompt-Based Structured Output (Approach 1): Demonstrates designing prompts for JSON output and validating with Pydantic and LangChain parsers.\n\n*   Model-Native Structured Output (Approach 2): Illustrates generating structured outputs using LangChain\u2019s `.with_structured_output(...)` for enforced structure during decoding.\n\n\n\nKey Takeaways", "mimetype": "text/plain", "start_char_idx": 2266, "end_char_idx": 4421, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "22d00a69-eba9-4b86-93d3-74e943663b99": {"__data__": {"id_": "22d00a69-eba9-4b86-93d3-74e943663b99", "embedding": null, "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0fd9c97d-f996-47cd-8c25-c43ef24e3e64", "node_type": "4", "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "06b24f218fb531c0d10bdfbd4c44adb25ca1020a924c1ef9f4af2154d8d3a665", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d965779b-6e75-4bb2-b4da-4ca3dbbb5ffa", "node_type": "1", "metadata": {"file_name": "From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\From Text to Data_ Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) Summary.docx", "file_size": 9082, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "7823a952e6f46342261db2fdfbf4600f6366d2cf0e5186b7937763aa7bbd55d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Key Takeaways\n\n\n\n*   Free-form LLM outputs are unreliable for integration into structured systems.\n\n*   Two main approaches for structured output are Prompt-Based (universal, but requires validation) and Model-Native (model-specific, guarantees structure).\n\n*   Prompt engineering can guide models to produce structured JSON, but still needs validation.\n\n*   Model-native structured output is superior, providing error-free, type-safe data by design, unlocking the full potential of LLMs in real-world, production-grade applications.\n\n\n\nOriginal Article Link: https://app.readytensor.ai/publications/LHMxs5Dtsv26", "mimetype": "text/plain", "start_char_idx": 4408, "end_char_idx": 5020, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fb9f2f20-e97e-4a38-ae31-b502186bec3e": {"__data__": {"id_": "fb9f2f20-e97e-4a38-ae31-b502186bec3e", "embedding": null, "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb112cbc-fb3e-434b-b18f-4de586538f07", "node_type": "4", "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "b0d4f9cb9de4814c82f3266e23f1ee756de10e38ebb341b0ab8b8afb2420631e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "64a347e2-310b-4572-b336-a28109d2b3a6", "node_type": "1", "metadata": {}, "hash": "59294de6cde7248eb0235ca92da3bb466618900c44d618574c02ed020966e887", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Summary: Getting Started with Agentic AI: Free APIs and Local LLM Options (AAIDC-Week2-Setup)\n\n\n\nIntroduction\n\nThis lesson focuses on enabling learners to engage with agentic AI using free Large Language Model (LLM) options. It introduces two primary approaches: utilizing free cloud APIs from providers like Groq and Google Gemini, or running models locally with Ollama. The course content is designed with low usage requirements, making it accessible without incurring costs for API access.\n\n\n\nEffortless LLM Switching with LangChain\n\nLangChain facilitates seamless transitions between various LLM providers, including Groq, Gemini, OpenAI, and local Ollama models. This flexibility allows users to adapt their setup with minimal configuration changes, ensuring continuity in their learning experience without altering code or prompts.\n\n\n\nOption 1: Use a Free Cloud API\n\n\n\nThis option involves leveraging cloud-based LLM services that offer free access tiers.\n\n\n\nGroq: Fast, Free Access to Open-Source LLMs\n\nGroq is an AI infrastructure provider that offers free API access to powerful open-source models like Llama 3 and Mixtral, hosted on their Language Processing Units (LPUs).\n\n\n\nAdvantages of Using Groq:\n\n- Free to use within generous limits, no credit card required.\n\n- Provides very fast responses due to LPUs.\n\n- Developer-friendly, ideal for learning and prototyping.\n\n- Features an OpenAI-style interface for easy prompt reuse.\n\n- Ready for integration with LangChain.\n\n\n\nHow to Set Up and Use Groq:\n\n1.  Sign Up: Go to https://console.groq.com and sign up.\n\n2.  Get API Key: Navigate to API Keys in the dashboard and create a new key (starts with gsk_...).\n\n3.  Add to Environment: Set GROQ_API_KEY in a .env file or export it in your terminal.\n\n4.  Install Package: pip install langchain_groq\n\n5.  Test Script: Use from langchain_groq import ChatGroq and llm = ChatGroq(model=\"llama3-8b-8192\") to invoke and print a response.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1940, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "64a347e2-310b-4572-b336-a28109d2b3a6": {"__data__": {"id_": "64a347e2-310b-4572-b336-a28109d2b3a6", "embedding": null, "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb112cbc-fb3e-434b-b18f-4de586538f07", "node_type": "4", "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "b0d4f9cb9de4814c82f3266e23f1ee756de10e38ebb341b0ab8b8afb2420631e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fb9f2f20-e97e-4a38-ae31-b502186bec3e", "node_type": "1", "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "bdfa4b048912e0bfa2590427719ea54efaba4b5eda8ceaff6414785ef5f3d666", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a4050874-9262-4feb-9555-1612005a72fc", "node_type": "1", "metadata": {}, "hash": "81efe69a26d050325847f534c427fb9d961eaf0335b160e37221f45d5e6c27e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Gemini: Access Google\u2019s LLMs Through a Free Developer Tier\n\nGemini, Google\u2019s suite of LLMs, can be accessed via the Gemini API using a developer key from Google AI Studio.\n\n\n\nAdvantages of Using Gemini:\n\n- No billing required to start; API key generation is instant with a Google account.\n\n- Developer-friendly usage limits suitable for learning and prototyping.\n\n- Demonstrates good performance in reasoning and coding tasks.\n\n- Supports multimodal inputs (text, images, etc.).\n\n- Integrates seamlessly with LangChain.\n\n\n\nHow to Set Up and Use Gemini:\n\n1.  Create API Key: Go to https://makersuite.google.com, sign in, click \"Get API Key\", and choose \"Create API Key in new project\" (key starts with AIza...).\n\n2.  Add to Environment: Set GOOGLE_API_KEY in a .env file or export it in your terminal.\n\n3.  Install Package: pip install langchain-google-genai\n\n4.  Test Script: Use from langchain_google_genai import ChatGoogleGenerativeAI and llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", ...) to invoke and print a response.\n\n\n\nOption 2: Run a Local LLM with Ollama\n\n\n\nOllama allows users to run powerful LLMs like Llama 3, Mistral, and Code Llama locally, providing full control and offline capability without API keys or rate limits.\n\n\n\nAdvantages of Using Ollama:\n\n- No API calls or rate limits; all processing occurs locally.\n\n- Fully offline functionality after initial model download.\n\n- Free and open-source, eliminating subscription or token costs.\n\n- Excellent for privacy-conscious development and experimentation.\n\n- Compatible with LangChain with minimal setup.\n\n\n\nSystem Requirements for Local LLMs:\n\nRunning local models, especially larger ones, demands substantial memory. Quantization is a technique that reduces memory usage by storing parameters in fewer bits, maintaining model quality for most tasks.\n\n\n\nMemory Rule (FP32 precision - 4 bytes per parameter):\n\n- Memory required (in GB) = Model size in billions \u00d7 4\n\n- Example: 7B model requires 28 GB, 13B model requires 52 GB.", "mimetype": "text/plain", "start_char_idx": 1944, "end_char_idx": 3949, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a4050874-9262-4feb-9555-1612005a72fc": {"__data__": {"id_": "a4050874-9262-4feb-9555-1612005a72fc", "embedding": null, "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb112cbc-fb3e-434b-b18f-4de586538f07", "node_type": "4", "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "b0d4f9cb9de4814c82f3266e23f1ee756de10e38ebb341b0ab8b8afb2420631e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "64a347e2-310b-4572-b336-a28109d2b3a6", "node_type": "1", "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "cbf08e4fb885926cd8a09ac3b1d91b29bd84786adc35b698d8beb26deae263f5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a0e59385-b271-43e1-93ab-710fa55b89c0", "node_type": "1", "metadata": {}, "hash": "4e8caf38e93a4c040088e9af956a94f69cfda1a4786404646f79ba7f3986af80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Memory Formula with Quantization:\n\n- Memory required (in GB) = Model size in billions \u00d7 bytes per parameter\n\n- Examples: 7B model in Q4 (0.5 bytes) requires 3.5 GB; 13B model in FP16 (2 bytes) requires 26 GB.\n\n\n\nMemory Requirements by Model Size (examples with quantization):\n\n- 1B: FP32 (4GB), FP16 (2GB), Q8 (1GB), Q4 (0.5GB)\n\n- 7B: FP32 (28GB), FP16 (14GB), Q8 (7GB), Q4 (3.5GB)\n\n- 13B: FP32 (52GB), FP16 (26GB), Q8 (13GB), Q4 (6.5GB)\n\n- Add 20-50% extra memory for overhead (activations, input tokens, temporary buffers).\n\n\n\nWhat will run on a Laptop GPU:\n\n- 8 GB GPU: 1B\u20133B models in Q4.\n\n- 16 GB GPU: 7B models in Q4 or Q8.\n\n- 32 GB+ GPU: 13B+ models, especially in FP16.\n\n\n\nWhen to Use Which Option (Comparison Table):\n\n\n\n| Feature          | Groq               | Gemini             | Ollama                |\n\n|------------------|--------------------|--------------------|-----------------------|\n\n| Setup            | Easy cloud setup   | Easy cloud setup   | Requires install      |\n\n| Speed            | Very fast          | Fast               | Varies by hardware    |\n\n| Cost             | Free tier          | Free tier          | Fully free (local)    |\n\n| Limits           | Rate caps apply    | Rate caps apply    | No rate limits        |\n\n| Offline?         | \u274c                 | \u274c                 | \u2705                     |\n\n| Great for        | Prototyping, speed | Reasoning, coding  | Privacy, full control |", "mimetype": "text/plain", "start_char_idx": 3953, "end_char_idx": 5382, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a0e59385-b271-43e1-93ab-710fa55b89c0": {"__data__": {"id_": "a0e59385-b271-43e1-93ab-710fa55b89c0", "embedding": null, "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb112cbc-fb3e-434b-b18f-4de586538f07", "node_type": "4", "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "b0d4f9cb9de4814c82f3266e23f1ee756de10e38ebb341b0ab8b8afb2420631e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a4050874-9262-4feb-9555-1612005a72fc", "node_type": "1", "metadata": {"file_name": "Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Getting Started with Agentic AI_ Free APIs and Local LLM Options (AAIDC-Week2-Setup) Summary.docx", "file_size": 10023, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "1638180ab69b9ba2b9d018b96b07b1f5334eece36d087171265ae63e97fa3235", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "OpenAI's GPT-OSS Models: Now Available for Local Use\n\nOpenAI has released open-source GPT-OSS models (gpt-oss-20b and gpt-oss-120b) that can be run locally with Ollama. These models are fully open-weight and offer high performance based on OpenAI's architecture. However, they demand significant hardware resources (20B needs ~16GB RAM, 120B needs ~60GB RAM), making cloud APIs more practical for most learners.\n\n\n\nFinal Notes\n\nUsers are encouraged to choose the LLM option that best suits their system and comfort level, as all options are viable for the course, and switching between them is straightforward with LangChain. The primary goal is to facilitate learning and experimentation without financial barriers.\n\n\n\nLink to the original article: https://app.readytensor.ai/publications/HMONylFlvgvC", "mimetype": "text/plain", "start_char_idx": 5386, "end_char_idx": 6188, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c4cb4d88-8397-432a-add8-cb059b8e3df0": {"__data__": {"id_": "c4cb4d88-8397-432a-add8-cb059b8e3df0", "embedding": null, "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00097974-57d0-4e06-a239-b8601266e61e", "node_type": "4", "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "e539c0c533cb75f6efd6b4bb52054ebd9ab85036e82017a42438f6ed50ad18fb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7a8858a5-2b39-4506-b45e-86ea0540975d", "node_type": "1", "metadata": {}, "hash": "80609ea48f16fa51ebdcb8f27a5d8ded3115e7b554b7d8d6134d41e85c05856f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary\n\n\n\nIntroduction\n\nThis lesson from Ready Tensor introduces Retrieval Augmented Generation (RAG) systems, a crucial technique for enabling Large Language Models (LLMs) to answer questions based on specific, up-to-date knowledge bases rather than just their pre-trained data.\n\n\n\nThe Ready Tensor Challenge: The Limitations of Simple LLM Solutions\n\nDirectly feeding large amounts of information to LLMs (like an entire publication or thousands of documents) is impractical due to token limits, high computational costs, increased latency, and scalability issues. Attempting to fine-tune LLMs on custom data for specific knowledge is also problematic due to significant costs (GPUs, dev time), high data volume requirements, fragility (retraining for policy changes), and the specialized ML expertise needed.\n\n\n\nEnter RAG: Retrieval-Augmented Generation\n\nRAG offers a solution by dynamically fetching relevant context on demand. It acts like a research assistant that retrieves specific information before generating a response. For Ready Tensor, this means when a user asks a question, the system identifies relevant sections from publications, and the LLM then provides a grounded, accurate answer using only that retrieved data. This approach eliminates the need for constant retraining when information changes.\n\n\n\nWhy RAG Wins\n\n* Scales Easily: Can search thousands of documents to retrieve only necessary information.\n\n* Stays Fresh: New information can be incorporated by re-embedding and storing, without retraining the LLM.\n\n* Cheaper: Avoids the high costs and complexities of retraining or fine-tuning.\n\n* More Transparent: Provides source citations, enhancing trust and verifiability.\n\n\n\nHow RAG Works: Two Phases\n\nEvery RAG system operates in two main phases:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1859, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7a8858a5-2b39-4506-b45e-86ea0540975d": {"__data__": {"id_": "7a8858a5-2b39-4506-b45e-86ea0540975d", "embedding": null, "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00097974-57d0-4e06-a239-b8601266e61e", "node_type": "4", "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "e539c0c533cb75f6efd6b4bb52054ebd9ab85036e82017a42438f6ed50ad18fb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c4cb4d88-8397-432a-add8-cb059b8e3df0", "node_type": "1", "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "505856e2d06dba5523a1a888abdb5940cfc44ba461e5f854891f423ca9819759", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7cf68e7c-a833-4fb9-a1e1-5e036ea996d9", "node_type": "1", "metadata": {}, "hash": "f92fd63795f5809cfe4fe63a2192297270e73626b451f6c6f6cbfdfc0eacabd4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "How RAG Works: Two Phases\n\nEvery RAG system operates in two main phases:\n\n\n\nPart 1: Building Your Knowledge Base (The Insertion Phase)\n\nThis phase involves preparing documents for intelligent, semantic search.\n\n1. Chunking Documents: Large documents are broken down into smaller, meaningful chunks to fit embedding model token limits and ensure coherent information within each piece.\n\n2. Converting Text to Vectors: Each chunk is transformed into a numerical vector that captures its semantic meaning. Similar topics have similar vectors, enabling semantic search.\n\n3. Storing in a Vector Database: The original text chunks and their vector representations are stored in a specialized database optimized for similarity search.\n\n\n\nPart 2: Smart Retrieval and Response (The Retrieval Phase)\n\nThis phase describes how a query is processed to generate a response.\n\n1. Question Embedding: The user's question is converted into a vector using the same embedding model used for documents.\n\n2. Similarity Search: The vector database is queried to find document chunks with embeddings closest to the question's embedding.\n\n3. Context Assembly: The most relevant chunks (e.g., 3-5 sections) are retrieved from the database.\n\n4. LLM Generation: These retrieved chunks, along with a system prompt, are sent to an LLM, which then generates a focused and accurate response based on the provided context.\n\n\n\nThe Gotchas: Potential Problems with RAG Systems\n\n* Infrastructure and Operational Costs: RAG requires vector database infrastructure, embedding services, and systems for managing document updates, adding to complexity and ongoing costs.\n\n* The Hallucination Problem: Even with relevant documents, LLMs might still generate plausible but fabricated information if the exact answer isn't explicitly in the retrieved context.\n\n* When Chunking Breaks Knowledge: Ineffective chunking can split a complete answer across multiple pieces, leading to incomplete or inaccurate retrieval and responses.\n\n* The Fresh Data Challenge: Maintaining an up-to-date knowledge base is critical, as old or outdated information can still be retrieved, leading to responses based on superseded techniques.", "mimetype": "text/plain", "start_char_idx": 1787, "end_char_idx": 3964, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7cf68e7c-a833-4fb9-a1e1-5e036ea996d9": {"__data__": {"id_": "7cf68e7c-a833-4fb9-a1e1-5e036ea996d9", "embedding": null, "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00097974-57d0-4e06-a239-b8601266e61e", "node_type": "4", "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "e539c0c533cb75f6efd6b4bb52054ebd9ab85036e82017a42438f6ed50ad18fb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7a8858a5-2b39-4506-b45e-86ea0540975d", "node_type": "1", "metadata": {"file_name": "Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Introduction to RAG (Retrieval Augmented Generation) Systems (AAIDC-Week2-Lesson-5) Summary.docx", "file_size": 9091, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "2bcc921e0a5a99fbf208e655c06d7fab1fb0af2566311fcec528281078dc77ea", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Why It Matters for Agentic AI\n\nRAG is a fundamental requirement for most valuable AI applications across industries, enabling agents to access current, specific, and domain-specific information beyond their training data. It transforms generic AI responders into intelligent reasoning systems capable of synthesizing insights, comparing approaches, and providing grounded analysis. RAG is the architectural foundation for sophisticated agentic systems, including LangGraph agents and multi-agent systems sharing knowledge bases.\n\n\n\nNext Steps: From Concept to Code\n\nWeek 3 of the program will focus on practical, hands-on implementation of RAG systems, covering vector database setup, embedding model selection, retrieval pipeline construction, and integration with LLMs to build functional chatbots and production-ready applications.\n\n\n\nOriginal Link: https://app.readytensor.ai/publications/3Ht58iNXuvS7", "mimetype": "text/plain", "start_char_idx": 3968, "end_char_idx": 4873, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a5f2c965-526a-44df-8a6b-f7c259a59b2b": {"__data__": {"id_": "a5f2c965-526a-44df-8a6b-f7c259a59b2b", "embedding": null, "metadata": {"file_name": "LLM_Function_Chaining_Guide_Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\LLM_Function_Chaining_Guide_Summary.docx", "file_size": 8791, "creation_date": "2025-11-09", "last_modified_date": "2025-11-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4b01a43b-900a-4ed5-a8c2-8f2cf7855774", "node_type": "4", "metadata": {"file_name": "LLM_Function_Chaining_Guide_Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\LLM_Function_Chaining_Guide_Summary.docx", "file_size": 8791, "creation_date": "2025-11-09", "last_modified_date": "2025-11-01"}, "hash": "0184118fd8791e352d36f36873338e5075410aefa08d4f2c0ca78e69c34e5ffa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0f6d7a31-7aff-4384-b20f-8e4273d5229e", "node_type": "1", "metadata": {}, "hash": "1959467ed0bd240f191b6a3d8ed43e2ed1af13a3b7218f9a488c37aadd7c96bd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Function Chaining in LLM Pipelines\n\n\n\nThis document summarizes the key concepts of function chaining in Large Language Model (LLM) pipelines, as presented in the article \"Building Intelligent Pipelines: A Guide to LLM Function Chaining (AAIDC-Week2-Lesson-3)\" from Ready Tensor.\n\n\n\nSummary\n\n\n\nFunction chaining is a fundamental approach for constructing robust, modular, and intelligent AI systems. It involves breaking down complex operations into smaller, focused, and manageable steps, rather than relying on a single, monolithic prompt or function. This method significantly enhances clarity, maintainability, flexibility, and overall power in AI applications.\n\n\n\nDirect Prompting vs. Chaining\n\n\n\nDirect Prompting\n\nDirect prompting is the simplest way to interact with a language model, suitable for quick experiments or one-off queries with minimal setup. It involves sending a direct prompt and receiving an immediate response, requiring clear and explicit instructions to minimize ambiguity.\n\n\n\nLimitations of Direct Prompting: It quickly becomes insufficient for use cases demanding more structure, reusability, dynamic input handling, or multi-stage reasoning.\n\n\n\nTemplates: Dynamic Input Insertion\n\nPrompt templates represent the next evolutionary step, bridging simple direct prompts and complex function chains. A template allows for defining a prompt structure once and reusing it with various inputs.\n\n\n\nAdvantages of Templates:\n\n Ensures consistency by maintaining the same structure and instructions across prompts.\n\n Facilitates reusability, allowing updates in a single location.\n\n Separates static instructions from dynamic content, improving clarity.\n\n Simplifies testing with different inputs.\n\n Crucial for production environments to handle dynamic user inputs, data from other systems, and varying user settings, leading to cleaner and more testable code.\n\n\n\nCreating Robust Templates: Effective templates separate fixed instructions from dynamic inputs, incorporate error handling for missing or incorrect data, and ensure consistent formatting.\n\n\n\nHow Function Chaining Works\n\n\n\nFunction chaining connects multiple AI-powered operations sequentially, where the output of one step serves as the input for the next. This mirrors real-world systems where tasks are handled by specialized stages, passing results along for further processing.\n\n\n\nKey Benefits of Function Chaining:\n\n Simplifies complex tasks by breaking them into smaller, more manageable components.\n\n Enables prompts to specialize in specific subtasks, leading to improved accuracy.\n\n Makes debugging easier by isolating errors to individual steps.\n\n Guarantees consistent and reliable output formatting across all stages.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2711, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0f6d7a31-7aff-4384-b20f-8e4273d5229e": {"__data__": {"id_": "0f6d7a31-7aff-4384-b20f-8e4273d5229e", "embedding": null, "metadata": {"file_name": "LLM_Function_Chaining_Guide_Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\LLM_Function_Chaining_Guide_Summary.docx", "file_size": 8791, "creation_date": "2025-11-09", "last_modified_date": "2025-11-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4b01a43b-900a-4ed5-a8c2-8f2cf7855774", "node_type": "4", "metadata": {"file_name": "LLM_Function_Chaining_Guide_Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\LLM_Function_Chaining_Guide_Summary.docx", "file_size": 8791, "creation_date": "2025-11-09", "last_modified_date": "2025-11-01"}, "hash": "0184118fd8791e352d36f36873338e5075410aefa08d4f2c0ca78e69c34e5ffa", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a5f2c965-526a-44df-8a6b-f7c259a59b2b", "node_type": "1", "metadata": {"file_name": "LLM_Function_Chaining_Guide_Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\LLM_Function_Chaining_Guide_Summary.docx", "file_size": 8791, "creation_date": "2025-11-09", "last_modified_date": "2025-11-01"}, "hash": "2e2871ba17e5f3cf4365c5a53a5c66f7fe0b30cb4dd57073a765c53b786d71d8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Sequential Chains: Output-to-Input Composition\n\nThis is the most basic form, where operations occur in a linear order (Output A from step 1 becomes Input for step 2, and so on). This pattern is highly effective for multi-stage reasoning tasks like:\n\n Research -> Analysis -> Recommendation\n\n Data extraction -> Transformation -> Summarization\n\n Question analysis -> Research -> Answer formulation\n\n\n\nLangChain Runnables\n\nLangChain provides a powerful Runnables API for implementing function chains using a functional programming style.\n\n\n\nPrompt + Model as Runnable: Allows binding a prompt template to an LLM to create a runnable chain for specific tasks.\n\n\n\nChaining Runnables with Pipe Operator: The pipe (|) operator in LangChain's Runnables API makes sequential chaining intuitive, connecting different runnable components (e.g., prompt | LLM | output parser).\n\n\n\nConclusion\n\n\n\nFunction chaining is essential for building scalable and intelligent AI applications. By modularizing tasks and connecting specialized steps, developers can create adaptable workflows that are easier to develop, maintain, and debug. This approach forms the backbone for advanced AI systems, orchestrating reasoning, retrieval, and generation into seamless, intelligent pipelines.\n\n\n\nOriginal URL: https://app.readytensor.ai/publications/X51gr9ZwohcW", "mimetype": "text/plain", "start_char_idx": 2715, "end_char_idx": 4047, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c4052aeb-504f-49f8-8de4-5dc39c3e3885": {"__data__": {"id_": "c4052aeb-504f-49f8-8de4-5dc39c3e3885", "embedding": null, "metadata": {"file_name": "Memory Management Strategies for Long AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies for Long AI Conversations.docx", "file_size": 8508, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a1bcb7bc-0fa3-4607-bceb-f3b9d4b04d6a", "node_type": "4", "metadata": {"file_name": "Memory Management Strategies for Long AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies for Long AI Conversations.docx", "file_size": 8508, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "c5295094b61f271ef4ca837740d39fa074d1db4bba895ab5d96494fb6da53018", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6b7266c9-60c1-46e3-bc5c-0b551781c4a0", "node_type": "1", "metadata": {}, "hash": "a6d1d47f04a885ddd61bfef03073d8aa9b8e2ef68474e191f38a10448c49c4a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Memory Management Strategies for Long AI Conversations\n\n\n\nIntroduction\n\nThis lesson explores methods for managing conversation memory in AI chat sessions, particularly when discussions become lengthy. It outlines common problems arising from unlimited chat history and presents three strategies to mitigate these issues.\n\n\n\nProblem: The Cost of Unlimited Chat History\n\nAs AI conversations extend, stuffing every interaction into the chat history leads to several challenges:\n\n  Token Limits: Most AI models have strict context window limits (e.g., 4k, 8k, 32k tokens), which can cause applications to fail when exceeded.\n\n  Cost Explosion: Sending vast amounts of redundant history with each request dramatically increases operational costs.\n\n  Context Pollution: Older, less relevant parts of the conversation can dilute the current context, leading to unfocused or confused AI responses.\n\n  Performance Issues: Processing large context windows is resource-intensive and slows down response times, negatively impacting user experience.\n\n\n\nThree Memory Management Strategies\n\n\n\n  1. The \"Stuff Everything In\" Strategy\n\n     Description: This straightforward approach involves keeping every single message in the conversation history.\n\n     Pros: Simple to implement.\n\n     Cons: Does not scale for long conversations, is expensive, and can lead to AI hallucination.\n\n     LangChain Implementation: ConversationBufferMemory.\n\n\n\n  2. Trim Older Messages (Sliding Window)\n\n     Description: This strategy retains only the most recent \"N\" messages (e.g., last 3\u20135 turns), effectively creating a sliding window of conversation.\n\n     Pros: Reduces prompt size, keeps context recent and relevant.\n\n     Cons: May result in the loss of important older context if the user revisits past topics.\n\n     LangChain Implementation: ConversationBufferWindowMemory.\n\n\n\n  3. Summarize or Refine Older History\n\n     Description: The most advanced method, where older parts of the conversation are summarized to retain key points rather than every word.\n\n     Pros: Retains essential context while significantly reducing prompt size, effective for focused, long conversations.\n\n     Cons: Summary generation adds complexity and potential cost, may lose subtle details during summarization.\n\n     LangChain Implementation: ConversationSummaryMemory.\n\n\n\nProtecting Your System Prompt\n\nRegardless of the memory strategy used, the system prompt\u2014which defines the AI's core behavior and role\u2014must always be retained. Frameworks like LangChain handle this automatically by keeping the system prompt separate from the dynamic conversation memory.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2621, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6b7266c9-60c1-46e3-bc5c-0b551781c4a0": {"__data__": {"id_": "6b7266c9-60c1-46e3-bc5c-0b551781c4a0", "embedding": null, "metadata": {"file_name": "Memory Management Strategies for Long AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies for Long AI Conversations.docx", "file_size": 8508, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a1bcb7bc-0fa3-4607-bceb-f3b9d4b04d6a", "node_type": "4", "metadata": {"file_name": "Memory Management Strategies for Long AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies for Long AI Conversations.docx", "file_size": 8508, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "c5295094b61f271ef4ca837740d39fa074d1db4bba895ab5d96494fb6da53018", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c4052aeb-504f-49f8-8de4-5dc39c3e3885", "node_type": "1", "metadata": {"file_name": "Memory Management Strategies for Long AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies for Long AI Conversations.docx", "file_size": 8508, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "12acfe47931cffedacf49b6fa1eb386c6578d5446d83f25b1478b515064220e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Hands-On Experiment: Comparing Memory Strategies\n\nA demonstration script is available to showcase the practical impact of these strategies on prompt size and performance. It simulates a long conversation using VAE publication questions, runs each strategy, and provides a comparison report of token usage. A video demonstration is also provided.\n\n\n\nCaution: Response Quality\n\nThis lesson primarily focuses on token usage and performance. The impact on response accuracy and quality is a separate, more advanced topic to be covered in Module 2.\n\n\n\nKey Takeaways\n\n  Memory strategies are critical for managing long AI conversations and should be chosen based on specific use cases.\n\n  Smart memory management can lead to significant token savings.\n\n  Different strategies can influence the quality of AI responses, not just operational costs.\n\n\n\nLink to Original Publication: https://app.readytensor.ai/publications/WCVvtUtH3N1o", "mimetype": "text/plain", "start_char_idx": 2625, "end_char_idx": 3551, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3ecc03b9-3a7c-43f3-ab6a-491069e6ba3f": {"__data__": {"id_": "3ecc03b9-3a7c-43f3-ab6a-491069e6ba3f", "embedding": null, "metadata": {"file_name": "Memory Management Strategies in AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies in AI Conversations.docx", "file_size": 8375, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9dfb3cb6-21c4-49b3-aa4e-e67375e4f18c", "node_type": "4", "metadata": {"file_name": "Memory Management Strategies in AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies in AI Conversations.docx", "file_size": 8375, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "0807d547fe7a2a585d6ad71ebae4ca8559947b92c68a8fd667bd0914a4510d80", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "26d9c2e9-ddb6-4de0-9ba9-148f271d2b4f", "node_type": "1", "metadata": {}, "hash": "c0cdaa53891fb89413a9a123c4af3c6b4d1064dedec8cc326ea025be62a577ed", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Memory Management Strategies for Long AI Conversations\n\n\n\nThis lesson addresses the challenges of managing long conversation histories in AI assistants, focusing on how to maintain context efficiently without incurring high costs or performance issues.\n\n\n\nProblem: The Cost of Unlimited Chat History\n\nAs chat sessions with AI assistants grow longer, several problems arise:\n\n  Token Limits: Most AI models have context window limitations, which can be easily exceeded by extensive conversation histories, leading to application failures.\n\n  Cost Explosion: Sending massive amounts of conversational data with each request significantly increases operational costs and reduces efficiency.\n\n  Context Pollution: Older, less relevant parts of a conversation can dilute the AI's focus, resulting in confused or unfocused responses.\n\n  Performance Issues: Processing large context windows demands more resources and time, negatively impacting user experience.\n\n\n\nThree Memory Management Strategies\n\n\n\n1.  The \u201cStuff Everything In\u201d Strategy\n\n    Description: This is the most basic approach, where every user and AI interaction is kept in the conversation history.\n\n    Pros: Simple to implement.\n\n    Cons: Does not scale for long conversations, is expensive, and can lead to AI \"hallucinations\" due to overwhelming context.\n\n    Implementation (LangChain): Uses `ConversationBufferMemory`.\n\n\n\n2.  Trim Older Messages (Sliding Window)\n\n    Description: This strategy retains only the most recent \"N\" messages (e.g., the last 3-5 turns) in the conversation history.\n\n    Pros: Reduces prompt size and keeps the context current and relevant.\n\n    Cons: Important older context might be lost if the user revisits earlier topics.\n\n    Implementation (LangChain): Uses `ConversationBufferWindowMemory` with a specified `k` (number of recent messages to keep).\n\n\n\n3.  Summarize or Refine Older History\n\n    Description: This advanced method involves summarizing older parts of the conversation to retain key points rather than every word.\n\n    Pros: Significantly reduces prompt size while preserving essential context, effective for focused, long conversations.\n\n    Cons: Summary generation adds computational complexity and cost, and subtle details might be lost during summarization.\n\n    Implementation (LangChain): Uses `ConversationSummaryMemory`.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2343, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "26d9c2e9-ddb6-4de0-9ba9-148f271d2b4f": {"__data__": {"id_": "26d9c2e9-ddb6-4de0-9ba9-148f271d2b4f", "embedding": null, "metadata": {"file_name": "Memory Management Strategies in AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies in AI Conversations.docx", "file_size": 8375, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9dfb3cb6-21c4-49b3-aa4e-e67375e4f18c", "node_type": "4", "metadata": {"file_name": "Memory Management Strategies in AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies in AI Conversations.docx", "file_size": 8375, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "0807d547fe7a2a585d6ad71ebae4ca8559947b92c68a8fd667bd0914a4510d80", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3ecc03b9-3a7c-43f3-ab6a-491069e6ba3f", "node_type": "1", "metadata": {"file_name": "Memory Management Strategies in AI Conversations.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Memory Management Strategies in AI Conversations.docx", "file_size": 8375, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "abbe7db0b3e85cddb2965876875edfa0b4f6888bdcb5f381d68f0d6d18d03bb9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Protecting Your System Prompt\n\nRegardless of the memory strategy chosen, the system prompt \u2013 which defines the AI's core role and behavior \u2013 must always be retained. Frameworks like LangChain automatically handle this by keeping the system prompt separate from the conversational memory.\n\n\n\nHands-On Experiment: Comparing Memory Strategies\n\nA demonstration script is provided to simulate long conversations and compare the impact of these strategies on prompt size and performance. This experiment uses VAE publication questions and generates a comparison report on token usage for each strategy. A video demonstration is available for practical insight.\n\n\n\nKey Takeaways\n\n  Memory strategies are crucial for managing long conversations in AI systems.\n\n  Smart memory management can lead to significant token savings.\n\n  Different memory strategies affect not only costs and performance but also the quality and accuracy of AI responses.\n\n\n\nWebsite: https://app.readytensor.ai/publications/WCVvtUtH3N1o", "mimetype": "text/plain", "start_char_idx": 2347, "end_char_idx": 3349, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1494240-d797-48b9-b378-feb1b581643e": {"__data__": {"id_": "b1494240-d797-48b9-b378-feb1b581643e", "embedding": null, "metadata": {"file_name": "Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_size": 8822, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f51aec7a-4a05-4c40-b591-05a71bf21752", "node_type": "4", "metadata": {"file_name": "Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_size": 8822, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "21d72a6cfec5e5cc02c77a5eae8c2fc8ca153f1715f38e24bb479d80629978c4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "98e50929-ed42-4f2f-8c6c-183a78de460e", "node_type": "1", "metadata": {}, "hash": "b3c842b9e74e8d87dd2cb91dc78cb4edd312bf8e36a858cb61a4024711897c03", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The webpage outlines the submission guidelines for Project 1 of the Agentic AI Developer Certification Program (AAIDC-Week4). This project requires participants to build a RAG-based AI assistant.\n\n\n\nTechnical Requirements\n\n Your project must include:\n\n - A RAG-based AI assistant application.\n\n - Integration with a vector database (e.g., FAISS, Chroma).\n\n - Embedded document corpus (from Ready Tensor publications, Wikipedia, or other approved sources).\n\n - A functional prompt \u2192 retrieval \u2192 response pipeline using LangChain.\n\n\n\nSubmission Deadlines\n\n Projects are reviewed monthly. The upcoming deadlines are:\n\n - September 05, 2025 \u2014 11:59 PM UTC\n\n - October 03, 2025 \u2014 11:59 PM UTC\n\n - November 03, 2025 \u2014 11:59 PM UTC\n\n - December 01, 2025 \u2014 11:59 PM UTC\n\n - January 05, 2026 \u2014 11:59 PM UTC\n\n - February 02, 2026 \u2014 11:59 PM UTC\n\n If a deadline is missed, the project will be reviewed in the subsequent month's cycle.\n\n\n\nStep-by-Step Submission Process\n\n 1. Before You Begin:\n\n  - Ensure you have a Ready Tensor account.\n\n  - Be enrolled in the Agentic AI Developer Certification Program (join via the Certifications page if not already enrolled).\n\n\n\n 2. Create Your Publication:\n\n  - The team lead creates a new publication on the Ready Tensor platform in their personal hub (not the 'Ready Tensor Certifications' hub).\n\n\n\n 3. Select the Module:\n\n  - In the \"Create Publication\" form, select the correct module (e.g., Module 1 for Project 1) from the dropdown.\n\n\n\n 4. Add Co-Authors:\n\n  - Include all teammates as co-authors. The team lead will be listed as the first author.\n\n\n\n 5. Link Your Code Repository:\n\n  - Upload the GitHub repository URL in the \"Code\" section.\n\n  - Important: Store API keys and sensitive data in a .env file, add it to .gitignore, and provide a .env_example for reproducibility without revealing actual values.\n\n\n\n 6. Follow Best Practices:\n\n  - Adhere to Ready Tensor's best practices for AI/ML project documentation.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1953, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "98e50929-ed42-4f2f-8c6c-183a78de460e": {"__data__": {"id_": "98e50929-ed42-4f2f-8c6c-183a78de460e", "embedding": null, "metadata": {"file_name": "Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_size": 8822, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f51aec7a-4a05-4c40-b591-05a71bf21752", "node_type": "4", "metadata": {"file_name": "Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_size": 8822, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "21d72a6cfec5e5cc02c77a5eae8c2fc8ca153f1715f38e24bb479d80629978c4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1494240-d797-48b9-b378-feb1b581643e", "node_type": "1", "metadata": {"file_name": "Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Project 1 Submission Guidelines - Agentic AI Developer Certification (AAIDC-Week4) Summary.docx", "file_size": 8822, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "cfff1b4bb7038a42ea5d172969b02c5336d9deb4d4a5dbf78fdc7cc2c4b03058", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "6. Follow Best Practices:\n\n  - Adhere to Ready Tensor's best practices for AI/ML project documentation.\n\n\n\n 7. Upload Supplementary Files:\n\n  - Upload any additional relevant files like PDFs, datasets, or documentation.\n\n\n\n 8. Final Review and Submit:\n\n  - Complete the submission before the deadline.\n\n\n\nBonus Tip\n\n Including a video demo of your application is highly recommended to enhance clarity and showcase your work. Upload it to YouTube and link it in your Ready Tensor publication.\n\n\n\nPublication Requirements Checklist\n\n - Published on Ready Tensor platform.\n\n - Correct Module selected (AAIDC - Module).\n\n - Created by the team lead.\n\n - All teammates added as co-authors.\n\n - GitHub repository linked under \"Models\" section.\n\n - Repository follows AI/ML code best practices.\n\n - Documentation follows AI/ML project best practices.\n\n\n\nCode Repository Requirements\n\n Your GitHub repository must:\n\n - Follow AI/ML code development best practices.\n\n - Be reproducible and runnable locally.\n\n - Include clear setup instructions, sample inputs, and expected outputs.\n\n - Score 70% or higher on the provided repository evaluation rubric.\n\n - Warning: Securely handle API keys and sensitive information using .env and .gitignore files, and provide a .env_example.\n\n\n\nEvaluation Process\n\n The Ready Tensor team will:\n\n 1. Review your Ready Tensor publication.\n\n 2. Clone and run the GitHub repository.\n\n 3. Test the RAG system's functionality.\n\n 4. Evaluate against technical and documentation rubrics.\n\n 5. Provide feedback and certification status.\n\n\n\nKey Reminders\n\n - Module selection is mandatory.\n\n - Only the team lead submits the publication.\n\n - The code must be fully functional and reproducible.\n\n - Both publication and code must meet a minimum quality threshold of 70%.\n\n\n\nNeed Help?\n\n Contact the Ready Tensor team on Discord for assistance.\n\n\n\nAdditional Resources\n\n - Repository Best Practices Guide\n\n - Technical Publication Rubric\n\n - Ready Tensor Publication Best Practices\n\n\n\nWebsite: https://app.readytensor.ai/publications/BblNcQTBi5Os", "mimetype": "text/plain", "start_char_idx": 1850, "end_char_idx": 3911, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "036fb84a-77b9-407b-97f8-982265dd1d0b": {"__data__": {"id_": "036fb84a-77b9-407b-97f8-982265dd1d0b", "embedding": null, "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c93fdbf5-72a8-4db2-bdf5-59b9728e3943", "node_type": "4", "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "1afdbab8eab7c05e4dfb67918177d63377ca3f0ddd63943dc567c1f632b48eaa", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "57d8286c-3d2e-4a38-aa54-24794706f2d6", "node_type": "1", "metadata": {}, "hash": "4b8685db205b193e4f9cc2413b30e2f81f7dd41469448050b78ee6e7ec8474bd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Prompt Engineering: Advanced Reasoning Techniques Summary\n\n\n\nThis lesson introduces three powerful \"reasoning\" techniques for Large Language Models (LLMs) to dramatically improve responses for complex tasks. It explains when and why to use each, clarifies their underlying mechanisms (structured text generation rather than true reasoning), and shows how they integrate into a modular prompt framework as a \"reasoning strategy\" component.\n\n\n\nGetting Better Answers from LLMs\n\nTo get better outputs from LLMs, structured prompting is essential. This involves guiding the model on how to approach a problem, not just what to do. LLMs, at their core, predict the next word in a plausible sequence, mimicking human reasoning patterns learned from vast training data.\n\n\n\nThe Three Reasoning Flows\n\n\n\nThese techniques provide different templates for LLMs to follow, optimized for various challenges:\n\n*   Chain of Thought (CoT): A linear progression that breaks down a problem, works through each piece systematically, and then synthesizes a conclusion. This mimics human problem-solving for logical puzzles and math.\n\n*   ReAct (Reasoning + Acting): Cycles between thinking and acting\u2014considering options, taking action, observing results, reflecting, and repeating. This is similar to human troubleshooting or decision-making with multiple variables.\n\n*   Self-Ask: Starts broad and narrows down by generating and answering sub-questions before combining them for a final solution. This reflects human research or analysis processes.\n\n\n\nChain of Thought (CoT)\n\n*   Description: Prompts the model to break a problem into smaller parts and work through them logically.\n\n*   When to Use It: Multi-step problems, logical reasoning, analytical tasks, or when the path to the answer matters and needs verification.\n\n*   Prompt Text: Simple versions include \"Let's think step by step.\" Detailed versions outline steps like \"Break down the problem,\" \"Address each step systematically,\" \"Show your reasoning,\" and \"Provide your final conclusion.\"\n\n*   When it Might Not Work: Simple tasks (adds unnecessary verbosity), ill-defined problems (can hallucinate plausible but wrong logic), and when misused (can make bad answers sound more convincing).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2234, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "57d8286c-3d2e-4a38-aa54-24794706f2d6": {"__data__": {"id_": "57d8286c-3d2e-4a38-aa54-24794706f2d6", "embedding": null, "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c93fdbf5-72a8-4db2-bdf5-59b9728e3943", "node_type": "4", "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "1afdbab8eab7c05e4dfb67918177d63377ca3f0ddd63943dc567c1f632b48eaa", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "036fb84a-77b9-407b-97f8-982265dd1d0b", "node_type": "1", "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "9a98784d067082ca020625fbd15e7ea8e900fe455fef49ffc86159152901c49d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "697258ed-63ec-4c56-a781-bde066f61770", "node_type": "1", "metadata": {}, "hash": "db3b34214139d4621413a9f3006b7d966797fa6e84e48da1fc56b7d36c605cf1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "ReAct (Reasoning + Acting)\n\n*   Description: Alternates between reasoning and taking actions to solve complex problems, often involving external information or tools.\n\n*   When to Use It: Problems requiring external information or tools, research tasks, multi-step workflows where intermediate results guide the next step, or situations where thinking alone is insufficient.\n\n*   Prompt Text: Simple versions use \"Thought, Action, Observation,\" while detailed versions include \"Reflection\" and repetition of steps. LangChain templates often integrate tool use.\n\n*   When it Might Not Work: Simple questions that don't require external information or when the model generates convincing but fake \"actions.\"\n\n\n\nSelf-Ask\n\n*   Description: A strategy where the model generates sub-questions, answers them sequentially, and then synthesizes a final answer.\n\n*   When to Use It: Problems that benefit from solving smaller sub-problems, exploring multiple angles, or explicit decomposition.\n\n*   Prompt Text: Simple prompts ask, \"To answer this question, what sub-questions should I ask first? Answer each one, then provide a final conclusion.\" Detailed versions outline breaking down, answering thoroughly, and synthesizing. LangChain examples use few-shot prompting to demonstrate the process.\n\n*   When it Might Not Work: Simple, direct questions, when sub-questions become more complex than the original, or for straightforward tasks where it creates unnecessary overhead.\n\n\n\nReality Check: Can LLMs Really Reason?\n\nLLMs do not truly \"reason\" but rather perform sophisticated pattern-matching and structured text generation based on their training data. These techniques work by triggering specific sequential text generation patterns that mimic human reasoning found in textbooks, documentation, and academic papers. The key is to match the reasoning technique to the problem type to improve results.\n\n\n\nIntegration with Modular Prompts\n\nThese reasoning techniques can be easily integrated into a modular prompt framework as a new \"reasoning strategy\" component, allowing control over how the LLM processes tasks while keeping other prompt elements unchanged.", "mimetype": "text/plain", "start_char_idx": 2238, "end_char_idx": 4395, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "697258ed-63ec-4c56-a781-bde066f61770": {"__data__": {"id_": "697258ed-63ec-4c56-a781-bde066f61770", "embedding": null, "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c93fdbf5-72a8-4db2-bdf5-59b9728e3943", "node_type": "4", "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "1afdbab8eab7c05e4dfb67918177d63377ca3f0ddd63943dc567c1f632b48eaa", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "57d8286c-3d2e-4a38-aa54-24794706f2d6", "node_type": "1", "metadata": {"file_name": "Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Prompt Engineering_ Advanced Reasoning Techniques Summary.docx", "file_size": 9085, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "769b3aa633b5a5e2875f4be998cc4477b89e206f8a21d0a308763ba7afe1c619", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Integration with Modular Prompts\n\nThese reasoning techniques can be easily integrated into a modular prompt framework as a new \"reasoning strategy\" component, allowing control over how the LLM processes tasks while keeping other prompt elements unchanged.\n\n\n\nConclusion\n\n*   Key Takeaways:\n\n    *   Know when to use each technique: Chain of Thought for logical, step-by-step problems; ReAct for multi-step investigations; Self-Ask for complex, multi-faceted questions.\n\n    *   They are not magic: These techniques enhance structure and thoroughness but do not guarantee correctness.\n\n    *   Modularity is key: These strategies integrate seamlessly into existing prompt frameworks.\n\n\n\nPractice Challenge: Apply these techniques to a complex question from your work or interests to observe their impact.\n\n\n\nOriginal Website: https://app.readytensor.ai/publications/3jI5t1hwF8wM", "mimetype": "text/plain", "start_char_idx": 4140, "end_char_idx": 5017, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fbe8f11d-5489-4577-b6c2-67194362d73b": {"__data__": {"id_": "fbe8f11d-5489-4577-b6c2-67194362d73b", "embedding": null, "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b2ad89f-0928-4a23-8a60-e111849f108e", "node_type": "4", "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "7a9f86ff01ed41a5f4b0ffe857eea9797dc6954dc6b39bda0776d1579b00faf0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c930e63c-d36a-4518-9cae-7fb8a47fcca4", "node_type": "1", "metadata": {}, "hash": "d05e8d4d39e9b139fd17f91463410a8829ceb663c374a462fcda4a20be2faf1d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Ready Tensor AI Lessons Summary\n\n\n\nYour First LLM Calls: Getting Started with Groq & LangChain (AAIDC-Week3-Lesson-1)\n\n\n\nThis lesson introduces the fundamentals of making Large Language Model (LLM) calls using Groq as the provider and LangChain as the framework. It focuses on three core concepts for building effective AI assistants:\n\n\n\nKey Topics\n\n* Making LLM Calls: Learn to initiate calls to LLMs using Groq and LangChain.\n\n* Grounded Questions: Ensure LLM responses are based strictly on provided content to prevent irrelevant or fabricated answers.\n\n* Multi-Turn Conversations: Implement memory to allow the AI assistant to maintain context across multiple user interactions.\n\n\n\nSetup and Installation\n\n* Prerequisites: Install 'langchain-groq', 'langchain', and 'pyyaml'.\n\n* API Key: Obtain a free API key from console.groq.com.\n\n\n\nExamples\n\n1. Simple LLM Call: Demonstrates a basic interaction where the LLM provides general information about Variational Autoencoders (VAEs) based on its training data.\n\n2. Publication-Specific Questions: Shows how to provide the LLM with specific publication content to get answers directly relevant to that text, preventing scope creep.\n\n3. Multi-Turn Conversations: Illustrates how to build conversational memory by appending previous questions and responses, enabling the AI to understand and respond to follow-up questions within context.\n\n\n\nMemory Management (Future Lessons)\n\nFor longer and more complex conversations, advanced memory handling techniques like summarization, compression, and the use of vector databases will be explored in subsequent lessons to ensure scalability.\n\n\n\nCode Quality and Professional Practice\n\nA video accompanies this lesson, emphasizing the importance of clean, maintainable, and professional code for AI projects. It covers coding standards for submissions, best practices for GitHub repositories, and how these habits contribute to a professional image.\n\n\n\nKey Takeaways\n\n* Ability to make basic LLM calls with Groq and LangChain.\n\n* Skill in grounding questions with external content for focused responses.\n\n* Understanding of multi-turn conversations and context management.\n\n\n\nNext Lesson\n\nThe next lesson will delve into crafting effective system prompts and prompt engineering to control the AI's style, tone, and quality of responses.\n\n\n\nOriginal Link: https://app.readytensor.ai/publications/BJbtjKH15JHb\n\n\n\n---", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2403, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c930e63c-d36a-4518-9cae-7fb8a47fcca4": {"__data__": {"id_": "c930e63c-d36a-4518-9cae-7fb8a47fcca4", "embedding": null, "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b2ad89f-0928-4a23-8a60-e111849f108e", "node_type": "4", "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "7a9f86ff01ed41a5f4b0ffe857eea9797dc6954dc6b39bda0776d1579b00faf0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fbe8f11d-5489-4577-b6c2-67194362d73b", "node_type": "1", "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "b069d7ee18662cc1f580b4cbb9640dc569390bde38861542c8be9e2ec11dc0c5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "731cc7ac-33a7-405e-b34b-5e062dd00380", "node_type": "1", "metadata": {}, "hash": "5f9519dbd6ac5c2a87e27291a4f4c3e8b89fe256558db35fe68ef11772322fee", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Original Link: https://app.readytensor.ai/publications/BJbtjKH15JHb\n\n\n\n---\n\n\n\nSystem Prompts: Your AI's Operating Manual (AAIDC-Week3-Lesson-2)\n\n\n\nThis lesson addresses critical challenges in developing AI assistants and presents system prompts as a foundational solution for ensuring reliability, safety, and consistency.\n\n\n\nProblems with Basic AI Assistants\n\n* Scope Creep: AI providing answers beyond the intended scope of information.\n\n* Pure Hallucination: AI fabricating information or details that are untrue.\n\n* Security Vulnerability: AI inadvertently revealing its internal instructions or sensitive data.\n\n* Other Issues: Inconsistent tone, generic brand voice, unpredictable output formats, and a lack of professional standards.\n\n\n\nThe Solution: System Prompts\n\nSystem prompts act as the \"operating manual\" for an AI, providing master instructions that define its personality, behavior, and boundaries for every response. They are crucial for transforming a generic chatbot into a focused, professional, and reliable agent.\n\n\n\nPurposes of System Prompts\n\n* Role and Personality: Clearly defines the AI's persona (e.g., a helpful research assistant).\n\n* Behavior and Tone: Shapes the AI's communication style (e.g., formal, concise, using bullet points).\n\n* Scope and Boundaries: Acts as a primary defense against hallucination and ensures responses are grounded in provided content.\n\n* Safety and Ethics: Embeds ethical guidelines, instructing the AI to refuse unethical requests or sensitive information disclosure.\n\n* Output Format: Dictates the structure of responses for consistency and clarity.\n\n\n\nAssembling Modular System Prompts\n\nThe lesson advocates for a modular approach to system prompt engineering, allowing individual components like role, tone, output constraints, and goals to be tweaked independently for adaptability and consistency.\n\n\n\nHands-On Testing\n\n* Basic System Prompt: Demonstrates how a simple prompt can effectively handle in-scope and out-of-scope questions but fails when faced with manipulative attempts to extract internal instructions.\n\n* Advanced System Prompt: Introduces specialized output constraints to address manipulative or malicious questions, successfully preventing the disclosure of internal instructions and maintaining a professional demeanor.\n\n\n\nKey Takeaway (Modular Prompt Engineering)\n\nEffective AI assistants are built by starting with core prompt components, adding specialized safety and ethical constraints, and rigorously testing in real-world scenarios, especially for edge cases.", "mimetype": "text/plain", "start_char_idx": 2329, "end_char_idx": 4879, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "731cc7ac-33a7-405e-b34b-5e062dd00380": {"__data__": {"id_": "731cc7ac-33a7-405e-b34b-5e062dd00380", "embedding": null, "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b2ad89f-0928-4a23-8a60-e111849f108e", "node_type": "4", "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "7a9f86ff01ed41a5f4b0ffe857eea9797dc6954dc6b39bda0776d1579b00faf0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c930e63c-d36a-4518-9cae-7fb8a47fcca4", "node_type": "1", "metadata": {"file_name": "Ready Tensor AI Lessons Summaries.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Ready Tensor AI Lessons Summaries.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "8d230e7200d30d3e3a09b12774b468fedd3b863b7c9b89f73f4535c6a04961d7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Key Takeaway (Modular Prompt Engineering)\n\nEffective AI assistants are built by starting with core prompt components, adding specialized safety and ethical constraints, and rigorously testing in real-world scenarios, especially for edge cases.\n\n\n\nThe Transparency Test\n\nIt's crucial to design system prompts with the assumption that they may become public. Prompts should be clear, ethical, and align with an organization's values, passing the \"Newspaper Test\" (would you be comfortable seeing it published on the front page of a major newspaper?). Ready Tensor emphasizes radical transparency.\n\n\n\nTesting System Prompts and Hallucinations (Video)\n\nA practical video demonstrates how to test and refine system prompts, including live injections and real-time results, to highlight the importance of system prompts for safety, reliability, and preventing hallucinations.\n\n\n\nFinal Takeaway: Ready Tensor\u2019s Vision\n\nSystem prompts are fundamental for creating trustworthy, production-ready AI assistants, shaping their personality, boundaries, and ethical framework in line with a mission of radical transparency and real-world readiness.\n\n\n\nOriginal Link: https://app.readytensor.ai/publications/t79Iyg4lva2t", "mimetype": "text/plain", "start_char_idx": 4636, "end_char_idx": 5841, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "792a6d39-5865-4c66-82f9-fa1a7d7897a3": {"__data__": {"id_": "792a6d39-5865-4c66-82f9-fa1a7d7897a3", "embedding": null, "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0bcce73-f841-4e88-9a59-516a5ea589d6", "node_type": "4", "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "6934ca1aa5d744520247c0bbfd47d950365a75761df1f15bdb93c4f8ed0a2e35", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4d7b0a81-3b06-421f-976b-38e70ec89f54", "node_type": "1", "metadata": {}, "hash": "c82e6cdf1c1628bfc231f9b8e1deed6e2f7ea07fa2506e2c664eb9fc4a5f1a5a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Real-World Applications and Use Cases of Agentic AI\n\n\n\nTL;DR\n\nAgentic AI systems are adaptive problem-solvers that understand plain language, pursue goals, adapt to change, use tools, and learn from memory. These capabilities make them powerful for complex, ambiguous, or dynamic tasks where rigid scripts fall short. However, they are not always the right tool: repetitive tasks may be cheaper with Robotic Process Automation (RPA), prediction is often best handled by traditional Machine Learning (ML), and many problems are solved with simple workflows.\n\n\n\nThe Promise of Agentic AI\n\nAgentic AI systems aim to be collaborative teammates capable of planning, adapting, and acting to achieve a goal. This is appealing to organizations across various sectors like healthcare, finance, logistics, and education.\n\n\n\nCore Strengths of Agentic AI\n\n1.  Understand and act on plain language: Agents can interpret natural language commands and determine necessary actions without predefined workflows.\n\n2.  Pursue goals, not just tasks: Agents are goal-seeking and can adapt their approach if initial methods fail or data is incomplete.\n\n3.  Adapt when the unexpected happens: They can re-plan and continue working even when faced with unforeseen changes or new information.\n\n4.  Use tools and delegate: Agents can integrate with external tools (databases, APIs) and even delegate tasks to other agents.\n\n5.  Build continuity with memory: Agents can remember past interactions and user preferences, making interactions feel personalized and coherent.\n\n\n\nClarifying the Boundaries\n\nAgentic AI is powerful but not a universal solution. Simpler tools are often more efficient and cost-effective for certain problems.\n\n\n\nWhat Agentic Systems Do Well:\n\nThey excel in ambiguous, dynamic, or multi-step problems requiring reasoning, memory, and tool use. Examples include research assistants sifting through messy sources or supply-chain agents adapting to shifting conditions.\n\n\n\nWhat They Cannot Do:\n\nAgents do not invent new scientific knowledge or guarantee truth. They operate within the confines of the tools and data provided. For tasks with zero error tolerance (e.g., life-critical decisions), human oversight and strict safeguards are crucial.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2239, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4d7b0a81-3b06-421f-976b-38e70ec89f54": {"__data__": {"id_": "4d7b0a81-3b06-421f-976b-38e70ec89f54", "embedding": null, "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0bcce73-f841-4e88-9a59-516a5ea589d6", "node_type": "4", "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "6934ca1aa5d744520247c0bbfd47d950365a75761df1f15bdb93c4f8ed0a2e35", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "792a6d39-5865-4c66-82f9-fa1a7d7897a3", "node_type": "1", "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "9872e3f0b91e106eb89993d101036348822ffed043855284451a5a2e1d811d7b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ddb7110c-6c6f-4360-8d6a-cf1f06daaa6f", "node_type": "1", "metadata": {}, "hash": "08b379b81caf5f3766f07eea5e650a69bb32431a8c5a1c68e4fc6706e6e68917", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "What They Can Do, But Shouldn't:\n\n-   Repetitive, deterministic processes (e.g., form-filling, data transfers): Better handled by Robotic Process Automation (RPA) due to lower cost and higher reliability.\n\n-   Pure prediction problems (e.g., credit risk forecasting, spam detection): Traditional machine learning models are faster, cheaper, and often more accurate.\n\n-   Tasks with fixed sequences: Workflows or scripted pipelines are more efficient.\n\n\n\nExamples Where Agentic AI Shines\n\n1.  Contextual Email Search: Resolves nicknames, clarifies intent, retrieves relevant messages, and suggests follow-ups.\n\n2.  Dynamic News Summarization: Queries multiple sources, filters duplicates, cross-checks for bias, and summarizes trends with timestamps.\n\n3.  Team Knowledge Retrieval: Scans communication channels, extracts decisions and action items, links relevant issues, and drafts status notes.\n\n\n\nReal-World Applications of Agentic AI\n\n-   Customer Support: Virtual assistants handling unpredictable queries, sentiment-aware routing.\n\n-   Marketing: Campaign assistants for creating copy, visuals, and collateral across channels.\n\n-   E-Commerce & Fashion: Shopping assistants providing personalized recommendations.\n\n-   Healthcare: Diagnostic assistants (human-in-the-loop) and radiology assistants highlighting anomalies.\n\n-   Finance: Personal finance assistants (with financial advisors in the loop for compliance).\n\n-   Education: Adaptive tutoring agents and automated grading assistants.\n\n-   Software Development: Coding assistants (e.g., GitHub Copilot) and DevOps agents.\n\n-   Legal: Contract review assistants and legal research assistants.\n\n-   Research: Scholarly research assistants for literature reviews and manuscript drafting.", "mimetype": "text/plain", "start_char_idx": 2243, "end_char_idx": 3990, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ddb7110c-6c6f-4360-8d6a-cf1f06daaa6f": {"__data__": {"id_": "ddb7110c-6c6f-4360-8d6a-cf1f06daaa6f", "embedding": null, "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b0bcce73-f841-4e88-9a59-516a5ea589d6", "node_type": "4", "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "6934ca1aa5d744520247c0bbfd47d950365a75761df1f15bdb93c4f8ed0a2e35", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4d7b0a81-3b06-421f-976b-38e70ec89f54", "node_type": "1", "metadata": {"file_name": "Real-World Applications and Use Cases of Agentic AI.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Real-World Applications and Use Cases of Agentic AI.docx", "file_size": 9692, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "cd04a48a8ee8aa4fe853daca4f492e19a5cf81be0fbfad28bdce925336a9b8de", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Your Decision Framework: The Right Tool for the Job\n\n-   Start with the stakes: For high-stakes tasks where failure causes serious harm, prioritize proven automation and human oversight.\n\n-   Assess the problem type:\n\n    -   Repetitive, perfect execution needed? -> RPA or traditional automation.\n\n    -   Fundamentally a prediction problem? -> Traditional ML model.\n\n    -   Fixed sequence but benefits from language understanding? -> Scripted workflow with LLM components.\n\n-   Check for agentic signals if none of the above fit:\n\n    -   Path depends on discovery? (\u2713 Agentic)\n\n    -   Reasoning across multiple sources needed? (\u2713 Agentic)\n\n    -   Approach varies by context/user intent? (\u2713 Agentic)\n\n    -   Tool selection part of problem-solving? (\u2713 Agentic)\n\n-   Reality check: Ensure clean data and reliable tools are available, consider unpredictability, and evaluate if the complexity is worth the benefit over simpler solutions.\n\n\n\nThe bottom line is that if clear \"if-then\" rules can define the process, an agent is likely unnecessary. Agentic systems are valuable for messy, ambiguous, and dynamic problems.\n\n\n\nWrapping Up: Powerful, But Not God-Like\n\nAgentic AI is an exciting technological shift, valuable for open-ended, dynamic, and tool-rich tasks requiring reasoning and adaptation. However, it's not magical and doesn't guarantee correctness or eliminate errors. Simpler tools are often better for many tasks. The key is knowing when and how to apply Agentic AI effectively.\n\n\n\nWebsite Link: https://app.readytensor.ai/publications/EbfPXrWQMeCh", "mimetype": "text/plain", "start_char_idx": 3994, "end_char_idx": 5559, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1017ef55-40f7-46f8-92e2-037e3a2e42a3": {"__data__": {"id_": "1017ef55-40f7-46f8-92e2-037e3a2e42a3", "embedding": null, "metadata": {"file_name": "System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_size": 8553, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0df1bdd0-68e6-4577-a03d-63ee31918d8f", "node_type": "4", "metadata": {"file_name": "System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_size": 8553, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "42c2a5e705fe9de8a1470cc70ec07301243a4ad318110a8131c33387c51d93bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6954397d-11d4-4da9-89f4-df89d08e8219", "node_type": "1", "metadata": {}, "hash": "fb48f0a625e3a743e3556fe89d80fe748d3a62dfe6b192dd706ccd46d9a97a07", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "System Prompts: Your AI's Operating Manual (AAIDC-Week3-Lesson-2) - Ready Tensor\n\n\n\nThis lesson highlights critical issues in AI assistants and introduces system prompts as a core solution for developing reliable and secure AI systems.\n\n\n\nProblems with AI Assistants\n\n  Scope Creep: The AI provides information beyond the specified document.\n\n  Pure Hallucination: The AI generates false information and explanations.\n\n  Security Vulnerability: The AI inadvertently discloses its internal instructions.\n\n  Other issues include inconsistent tone, lack of brand alignment, varied output formats, and failure to meet professional standards.\n\n\n\nThe Solution: System Prompts\n\nSystem prompts are foundational instructions that define an AI's personality, behavior, and limitations for all responses. They convert a generic chatbot into a focused, professional, and dependable agent.\n\n\n\nFunctions of System Prompts\n\n  Role and Personality: Establish the AI's identity (e.g., research assistant, customer support).\n\n  Behavior and Tone: Determine the AI's communication style (e.g., friendly, formal, bullet points).\n\n  Scope and Boundaries: Serve as the initial defense to control the AI's conversational topics, preventing hallucinations. For example, \"Only answer based on the provided publication. If the question goes beyond the scope, politely refuse.\"\n\n  Safety and Ethics: Guide the AI's ethical conduct, ensuring it declines unethical requests, protects sensitive information, and provides necessary disclaimers.\n\n  Output Format: Ensure consistent and professional response structures (e.g., bulleted lists, numbered summaries).\n\n\n\nModular System Prompt Assembly\n\nSystem prompts can be constructed using modular elements like role, tone, output constraints, and goals, enabling individual adjustments without extensive rewrites.\n\n\n\nHands-On Testing of Modular System Prompts\n\n  Basic System Prompt: Effective for direct questions within or clearly outside the scope, but fails to protect internal instructions from manipulative queries.\n\n  Advanced System Prompt: Explicitly designed to counter manipulative or malicious questions through specialized output constraints. Successfully refuses to reveal internal instructions and redirects users professionally.\n\n\n\nKey Learning\n\nModular system prompt engineering is vital. It involves building with core components, integrating specific safety and ethical constraints, and rigorously testing in real-world scenarios to create trustworthy and secure AI assistants.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2513, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6954397d-11d4-4da9-89f4-df89d08e8219": {"__data__": {"id_": "6954397d-11d4-4da9-89f4-df89d08e8219", "embedding": null, "metadata": {"file_name": "System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_size": 8553, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0df1bdd0-68e6-4577-a03d-63ee31918d8f", "node_type": "4", "metadata": {"file_name": "System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_size": 8553, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "42c2a5e705fe9de8a1470cc70ec07301243a4ad318110a8131c33387c51d93bc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1017ef55-40f7-46f8-92e2-037e3a2e42a3", "node_type": "1", "metadata": {"file_name": "System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\System Prompts_ Your AI_s Operating Manual (AAIDC-Week3-Lesson-2) Summary.docx", "file_size": 8553, "creation_date": "2025-11-09", "last_modified_date": "2025-11-09"}, "hash": "c41c8716ddd8b074fc775752954e42aca5e5d22dfd6fae1d6a4f89ff9c254b1e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Key Learning\n\nModular system prompt engineering is vital. It involves building with core components, integrating specific safety and ethical constraints, and rigorously testing in real-world scenarios to create trustworthy and secure AI assistants.\n\n\n\nThe Transparency Test: Should Your System Prompt Be Secret?\n\n  System prompts are prone to leakage, so they should be treated as potentially public.\n\n  Transparency Principle: If a system prompt cannot stand public scrutiny, it requires revision. An AI's core characteristics should be openly shared.\n\n  \"Newspaper Test\": A prompt should be acceptable for publication on a major newspaper's front page.\n\n  Ready Tensor's Standard: Promotes radical transparency in system prompt design to foster trust.\n\n  Examples: Good prompts are clear and ethical; bad prompts encourage deceptive behavior.\n\n\n\nTesting System Prompts and Hallucinations (Video)\n\nA video demonstrates practical methods for testing and refining system prompts in agentic AI systems, illustrating how to prevent hallucinations and enhance safety.\n\n\n\nFinal Takeaway: Ready Tensor\u2019s Vision\n\nSystem prompts are the cornerstone for developing trustworthy and production-ready AI assistants, aligning their personality, boundaries, and ethics with organizational values. Ready Tensor champions radical transparency and real-world applicability in prompt design.\n\n\n\nLink: https://app.readytensor.ai/publications/t79Iyg4lva2t", "mimetype": "text/plain", "start_char_idx": 2265, "end_char_idx": 3700, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "67a434d8-9e8f-4d23-b274-2438dbbfea46": {"__data__": {"id_": "67a434d8-9e8f-4d23-b274-2438dbbfea46", "embedding": null, "metadata": {"file_name": "The Core Components of AI Agents Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\The Core Components of AI Agents Summary.docx", "file_size": 8668, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "df5a9a5e-98bd-4ad8-a6dc-efbb94c67134", "node_type": "4", "metadata": {"file_name": "The Core Components of AI Agents Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\The Core Components of AI Agents Summary.docx", "file_size": 8668, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "8bf7d1a52da1122a6defec40939375f6e4ab3ddf10d17f27027a7df14653f96d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1cd3ea53-af63-4fcf-8861-9b9018c9627f", "node_type": "1", "metadata": {}, "hash": "225a94674651b56f4b4aba2548a7b09e039a5ae7e37b7101aafb522ff96fdf6a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The Core Components of AI Agents Summary\n\n\n\nTL;DR\n\nAgentic systems are composed of two main layers: architectural components (LLMs, tools, memory) and behavioral components (planning, reasoning, and refinement). This lesson explains how these layers interact to build intelligent, goal-driven AI.\n\n\n\nBuilding Smarter Systems: What\u2019s Really Inside an Agent?\n\nAgentic AI systems move beyond static workflows to plan, decide, and act. They are composed of architectural parts that provide raw capabilities and designed behaviors that enable intelligent action. This lesson explores these two key ingredients: architectural components and behavioral components, and how they are orchestrated for autonomy.\n\n\n\nThe Architectural Components\n\nThese are the foundational building blocks of agentic systems:\n\n\n\nLarge Language Model (LLM) \u2013 The Brain\n\nThe LLM is central to any AI agent, processing text input and generating text output. It provides language understanding and generation, acting as the central processing unit for human-AI interaction.\n\n\n\nTools \u2013 The Hands\n\nTools allow agents to perform actions beyond their inherent knowledge, such as searching the web, querying databases, or calling APIs. They transform an agent from a \"talker\" to a \"doer.\"\n\n\n\nMemory \u2013 The Recall\n\nMemory provides agents with continuity and consistency across interactions.\n\nShort-term memory: Maintains coherence within an ongoing conversation session.\n\nLong-term memory: Persists information across multiple sessions, like user preferences or past questions.\n\n\n\nThe Behavioral Components\n\nThese are intentional design choices\u2014patterns and control flows\u2014that guide an agent\u2019s behavior, making it smarter and more reliable.\n\n\n\nPlanning \u2013 Breaking Down Complexity\n\nAgents can break down complex tasks into manageable steps, similar to human problem-solving. Strategies like Chain-of-Thought prompting or self-ask guide agents to think in steps, leading to more aligned and human-like responses.\n\n\n\nReasoning \u2013 Working It Through\n\nAgents can be guided to weigh options, utilize tools, and justify their choices, similar to human reasoning. Patterns like ReAct promote systematic, transparent, and trustworthy reasoning.\n\n\n\nRefinement \u2013 Improving the Draft\n\nAgents can iterate and improve their outputs through techniques like self-critique or the Reflection pattern, where one agent critiques another's work. This enhances the sharpness and reliability of the results.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2444, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1cd3ea53-af63-4fcf-8861-9b9018c9627f": {"__data__": {"id_": "1cd3ea53-af63-4fcf-8861-9b9018c9627f", "embedding": null, "metadata": {"file_name": "The Core Components of AI Agents Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\The Core Components of AI Agents Summary.docx", "file_size": 8668, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "df5a9a5e-98bd-4ad8-a6dc-efbb94c67134", "node_type": "4", "metadata": {"file_name": "The Core Components of AI Agents Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\The Core Components of AI Agents Summary.docx", "file_size": 8668, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "8bf7d1a52da1122a6defec40939375f6e4ab3ddf10d17f27027a7df14653f96d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "67a434d8-9e8f-4d23-b274-2438dbbfea46", "node_type": "1", "metadata": {"file_name": "The Core Components of AI Agents Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\The Core Components of AI Agents Summary.docx", "file_size": 8668, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "f43f60af8d0b93f650e62dc3929adc951f1afaa734c5db9f74ba5f1ce5ba3737", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Refinement \u2013 Improving the Draft\n\nAgents can iterate and improve their outputs through techniques like self-critique or the Reflection pattern, where one agent critiques another's work. This enhances the sharpness and reliability of the results.\n\n\n\nAutonomy and Decision Control \u2013 Choosing the Next Move\n\nAutonomy is a defining characteristic of agentic systems, allowing them to choose their next actions rather than following fixed instructions. They adapt to ambiguity, failure, or new information by embedding mechanisms for tool selection, retries, stop conditions, and routing. This transforms a static AI assistant into a dynamic agent.\n\n\n\nOrchestration \u2013 Designing the Full System\n\nOrchestration is the process of composing agents, tools, prompts, and control logic into a cohesive system. This involves selecting system patterns (Chain, Supervisor, Network, Hierarchy), defining data flow between nodes, and implementing fault tolerance mechanisms like fallbacks, retries, timeouts, and stop conditions. A well-designed system is intelligent not just at each step, but in how all the steps work together.\n\n\n\nWhat Comes Next\n\nThe upcoming lessons and modules will provide hands-on experience to build real, working AI agents, focusing on implementing these architectural, behavioral, and orchestration concepts.\n\n\n\nReflect and Test Your Understanding\n\nA video is provided to help reinforce the understanding of the core components of AI agents.\n\n\n\nOriginal Link: https://app.readytensor.ai/publications/O8OHY0ehCvdr", "mimetype": "text/plain", "start_char_idx": 2199, "end_char_idx": 3722, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "de5066a9-0a84-4bfa-be2a-d7f2abe6076a": {"__data__": {"id_": "de5066a9-0a84-4bfa-be2a-d7f2abe6076a", "embedding": null, "metadata": {"file_name": "Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_size": 8224, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8efa28c5-8856-4ff4-b3c4-bccb795d3ea8", "node_type": "4", "metadata": {"file_name": "Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_size": 8224, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "hash": "82a7f05d7d23e0217c551972a7b1c85d0d5003a6a3faa7c6d6b7af6d387b41a8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e21033d1-92da-49e4-b2e1-cb6ac6ba4823", "node_type": "1", "metadata": {}, "hash": "9506139ee2c998d336ba4a84afe17606d45e45957e589862723a77562fb85130", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Vector Databases: Building a Semantic Retrieval System (AAIDC-Week2-Lesson-4b)\n\n\n\nThis lesson provides a comprehensive guide to building a vector database pipeline for semantic retrieval. It emphasizes practical implementation using real documents, embedding models, and ChromaDB. This foundational knowledge is crucial for developing agentic AI projects.\n\n\n\nKey Steps and Concepts:\n\n\n\n1.  Choosing an Embedding Model: The process begins with selecting an appropriate embedding model (e.g., all-MiniLM-L6-v2 from Hugging Face) to convert text into numerical vector embeddings. The choice of model impacts how effectively meaning is captured from the text.\n\n\n\n2.  Document Preparation: Documents are structured as Document objects, including page_content (the text) and metadata (for filtering and organization). For large documents, intelligent chunking is essential to avoid loss of granularity and exceeding model token limits. Chunks of 300-800 tokens are generally recommended for optimal retrieval performance. The RecursiveCharacterTextSplitter from LangChain is used for intelligent text splitting with chunk_overlap to preserve context across boundaries.\n\n\n\n3.  Vector Store Creation: The prepared documents and their embeddings are then stored in a vector database, such as ChromaDB. ChromaDB handles the storage of vectors and the creation of a similarity index, making it easy to perform semantic searches.\n\n\n\n4.  Semantic Search: Once the vector store is populated, semantic queries can be executed. The similarity_search_with_score method returns documents based on conceptual similarity, rather than exact keyword matches. Lower scores indicate higher relevance (e.g., cosine distance).\n\n\n\nProduction Considerations:\n\n\n\n*   Performance and Persistence: While in-memory databases like FAISS or temporary Chroma instances are great for prototyping, production systems require persistent storage (e.g., disk-backed or distributed configurations offered by Chroma, Qdrant, Weaviate) to ensure data durability and scalability.\n\n*   Update Strategies: Important considerations include how to re-embed new documents, support real-time updates, and manage changes to the embedding model in a production environment.\n\n\n\nImportance for Agentic AI:", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2251, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e21033d1-92da-49e4-b2e1-cb6ac6ba4823": {"__data__": {"id_": "e21033d1-92da-49e4-b2e1-cb6ac6ba4823", "embedding": null, "metadata": {"file_name": "Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_size": 8224, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8efa28c5-8856-4ff4-b3c4-bccb795d3ea8", "node_type": "4", "metadata": {"file_name": "Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_size": 8224, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "hash": "82a7f05d7d23e0217c551972a7b1c85d0d5003a6a3faa7c6d6b7af6d387b41a8", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "de5066a9-0a84-4bfa-be2a-d7f2abe6076a", "node_type": "1", "metadata": {"file_name": "Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ Building a Semantic Retrieval System Summary.docx", "file_size": 8224, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "hash": "498391091f10a11ce8b744489217f992c675631ff2c512c0c17045ac4dc3b418", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Importance for Agentic AI:\n\n\n\nThis semantic retrieval system forms the fundamental memory layer for agentic AI. It enables AI agents to access external knowledge by translating natural language questions into precise, relevant contexts. This capability is vital for developing intelligent, reliable, and dynamic AI systems that can reason over information.\n\n\n\nConclusion:\n\nBuilding an effective semantic retrieval system involves converting documents into searchable embeddings, implementing intelligent chunking strategies, and understanding deployment considerations for production. This system is the core memory for agentic AI, and its retrieval quality directly influences the intelligence and utility of AI agents. Further experimentation with chunk sizes and embedding models is encouraged to optimize search relevance and specificity.\n\n\n\nWebsite Link: https://app.readytensor.ai/publications/hwjIdxHZGASQ", "mimetype": "text/plain", "start_char_idx": 2225, "end_char_idx": 3137, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "aa51c1ef-9695-4ad4-ae7a-7a309764a755": {"__data__": {"id_": "aa51c1ef-9695-4ad4-ae7a-7a309764a755", "embedding": null, "metadata": {"file_name": "Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_size": 8950, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "42556d54-3e79-43cb-a9c8-39509465a212", "node_type": "4", "metadata": {"file_name": "Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_size": 8950, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "hash": "f62c9038b91d3c0b0733f842597cf42f7ed76eb0676c4e1e2395a94487bff0ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "463a9b72-bce4-4882-8360-855f3df9c411", "node_type": "1", "metadata": {}, "hash": "a1e010b992960d2d3c4b68abaf4ca8ff93be0b4be7eb98f074971dcdd2496f8d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Vector Databases: How AI Finds Meaning, Not Just Keywords (AAIDC-Week2-Lesson-4a)\n\n\n\nSummary\n\n\n\nThis lesson introduces the retrieval challenge at the heart of intelligent AI systems. You'll learn how vector databases solve this challenge by enabling search based on meaning, not just exact words. You'll understand how embeddings convert language into math and how that unlocks semantic understanding for the agentic AI systems you'll build.\n\n\n\nNote: If you are already familiar with vector databases and embeddings concepts, you can skip directly to Lesson 3B: Building a Semantic Retrieval System, which covers hands-on implementation and includes a video with practical production insights from Ready Tensor's engineering team.\n\n\n\nThe Search Problem Every AI Builder Faces\n\nWhen building an AI assistant for a data science team's knowledge base, the system needs to find genuinely helpful documents, not just those with matching keywords. For instance, a search for \"How do I handle missing values in my dataset?\" should ideally find a document titled \"Strategies for Dealing with Incomplete Data Records,\" even though the exact phrasing doesn't match. This is the core retrieval problem for AI systems: how to retrieve semantically relevant content, not just textually similar ones.\n\n\n\nA Real Challenge at Ready Tensor\n\nThis problem was encountered during the development of the Ready Tensor platform. Users' search queries for AI publications often didn't align with how authors titled their work. For example, a search for \"neural network tutorials\" might need to retrieve articles titled \"Deep Learning Fundamentals\" or \"Multi-Layer Perceptron Explained.\" Keyword matching proved inadequate and often misleading, necessitating a smarter method to connect concepts expressed in different words.\n\n\n\nWhy Keywords Fail\n\nKeyword search relies on exact matches, failing to recognize synonyms or related concepts. For example, a search for \"How do I prevent overfitting?\" would miss documents discussing \"regularization techniques,\" \"cross-validation,\" or \"dropout and early stopping,\" even though these are all solutions to overfitting. Human readers make these semantic connections instantly, but traditional search systems do not.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2233, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "463a9b72-bce4-4882-8360-855f3df9c411": {"__data__": {"id_": "463a9b72-bce4-4882-8360-855f3df9c411", "embedding": null, "metadata": {"file_name": "Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_size": 8950, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "42556d54-3e79-43cb-a9c8-39509465a212", "node_type": "4", "metadata": {"file_name": "Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_size": 8950, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "hash": "f62c9038b91d3c0b0733f842597cf42f7ed76eb0676c4e1e2395a94487bff0ee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "aa51c1ef-9695-4ad4-ae7a-7a309764a755", "node_type": "1", "metadata": {"file_name": "Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\Vector Databases_ How AI Finds Meaning, Not Just Keywords.docx", "file_size": 8950, "creation_date": "2025-11-09", "last_modified_date": "2025-11-08"}, "hash": "4acbf16c44680d8f8c977ab1d72272cdf0bdd15506c51d3a512575b8d424b163", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The Shift: From Tokens to Meaning\n\nVector databases address this by comparing ideas mathematically. Text is converted into numerical representations called embeddings, which are vectors in a high-dimensional space. In this space, similar meanings are positioned close together, regardless of the original words. A query like \"How do I prevent overfitting?\" becomes a vector, and the system searches for nearby vectors in meaning, retrieving relevant content based on intent rather than exact phrasing.\n\n\n\nWhat is an Embedding?\n\nAn embedding is an array of numbers (a vector) representing a piece of data in a high-dimensional space. Each dimension captures an aspect of the data's meaning. The key principle is that semantically similar items will have similar embedding vectors, appearing close to each other in this space. For example, the embeddings for \"cat\" and \"dog\" would be closer than either is to \"car\" due to shared semantic relationships. Embeddings transform fuzzy human language into structured, machine-readable data without losing meaning.\n\n\n\nWhy This Changes Everything for Retrieval\n\nEmbeddings enable searching in a way that aligns with human thought processes. A search for \"deep learning\" also considers \"neural networks,\" \"CNNs,\" and \"transformers\" because their embeddings are close in vector space. This is particularly crucial in AI, where concepts can be described differently across various contexts (research, engineering, business). Embedding-based systems bridge these linguistic gaps, powering semantic search engines, recommendation systems, and intelligent retrieval in agentic AI applications.\n\n\n\nThe Foundation for Intelligent AI\n\nVector databases are fundamental to agentic AI systems. Their ability to mathematically understand meaning is critical for retrieving relevant documents, recommending content, and grounding AI responses in factual knowledge. The effectiveness of an AI system directly depends on the quality of its embeddings and the efficiency of its vector database.\n\n\n\nUp Next: Build One Yourself\n\nThe next lesson will provide a practical implementation. You will learn to set up an embedding model, store documents in a vector database, and execute semantic search queries. It will also cover best practices such as chunking, metadata management, and selecting appropriate vector database solutions.\n\n\n\nOriginal Link: https://app.readytensor.ai/publications/Zdrul0fG17Mg", "mimetype": "text/plain", "start_char_idx": 2237, "end_char_idx": 4660, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "285dda77-e923-417a-8f0e-3e73d59a00b7": {"__data__": {"id_": "285dda77-e923-417a-8f0e-3e73d59a00b7", "embedding": null, "metadata": {"file_name": "What is Agentic AI Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\What is Agentic AI Summary.docx", "file_size": 8878, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2e179271-37d9-438b-ba9c-46a0bea68be6", "node_type": "4", "metadata": {"file_name": "What is Agentic AI Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\What is Agentic AI Summary.docx", "file_size": 8878, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "7000b3f6883579e8312de77beb535185a594c519c0425c50373e93a9b1c9764e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "84fe8f8e-b99e-429c-a218-0bc21a11a166", "node_type": "1", "metadata": {}, "hash": "57cc4133d3cddad54a186bd4d97c30ef45e0295000cd8a0b834c00879e09921d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "What is Agentic AI (AAIDC-Week1-Lesson-1)\n\n\n\nIntroduction to Agentic AI Systems\n\n  Overview: Agentic AI gives AI systems autonomy, moving from rigid workflows to adaptive agents and collaborative multi-agent teams. This lesson introduces the spectrum of AI autonomy: predictable workflows, decision-making agents, and coordinated multi-agent systems.\n\n\n\nWhat You'll Learn This Week\n\n  By the end of this week, you'll have a solid understanding of:\n\n  - The meaning and significance of Agentic AI\n\n  - What AI Agents are and how they function\n\n  - Key differences between workflows and AI agents\n\n  - Core elements/components that make up AI agents\n\n  - Real-world applications of Agentic AI\n\n  - Popular tools and frameworks used in the field\n\n\n\nWhy Agentic AI Matters\n\n  Traditional software and earlier AI systems operated based on fixed rules and step-by-step instructions. Agentic AI introduces a significant change by allowing systems to pursue user-provided goals in flexible, adaptive ways. These systems can plan, make choices, adapt to obstacles, and act autonomously. This shift from scripted execution to autonomous decision-making transforms AI from a mere tool into a collaborator.\n\n\n\nWhat is Agentic AI?\n\n  At its core, Agentic AI is the autonomy engine for AI systems. It comprises methods and design principles that enable AI to operate with initiative, moving through a progression:\n\n\n\n  1.  Large Language Model (LLM) Workflows:\n\n      Here, developers define the logic and flow. The LLM acts as a component within a predictable pipeline where every step is laid out, and the structure is fixed, even if outputs vary.\n\n\n\n  2.  Single-Agent Systems:\n\n      In contrast to rigid pipelines, the AI itself makes decisions. An agent determines how to solve a problem, selects tools, and defines the order of operations, engaging in reasoning and choosing rather than just executing a flow.\n\n\n\n  3.  Multi-Agent Systems:\n\n      This involves multiple agents, each with a specific role, collaborating on tasks. Coordination can be centralized (e.g., a supervisor agent) or decentralized (e.g., peers exchanging information). This enables more complex, human-like teamwork.\n\n\n\n  LLM workflows are covered in Module 1, while single and multi-agent systems are explored in Modules 2 and 3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2297, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "84fe8f8e-b99e-429c-a218-0bc21a11a166": {"__data__": {"id_": "84fe8f8e-b99e-429c-a218-0bc21a11a166", "embedding": null, "metadata": {"file_name": "What is Agentic AI Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\What is Agentic AI Summary.docx", "file_size": 8878, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2e179271-37d9-438b-ba9c-46a0bea68be6", "node_type": "4", "metadata": {"file_name": "What is Agentic AI Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\What is Agentic AI Summary.docx", "file_size": 8878, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "7000b3f6883579e8312de77beb535185a594c519c0425c50373e93a9b1c9764e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "285dda77-e923-417a-8f0e-3e73d59a00b7", "node_type": "1", "metadata": {"file_name": "What is Agentic AI Summary.docx", "file_path": "C:\\Users\\dell\\Programming\\agentic_ai_project\\data\\What is Agentic AI Summary.docx", "file_size": 8878, "creation_date": "2025-11-09", "last_modified_date": "2025-10-31"}, "hash": "dba9a1a3ca54e1222587e40c58d0501c2f933e9995860291075a100453fe57c7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "LLM workflows are covered in Module 1, while single and multi-agent systems are explored in Modules 2 and 3.\n\n\n\nLLM Workflows\n\n  Defined as a pipeline connecting multiple steps into a repeatable process (e.g., customer support assistants, domain-specific research tools).\n\n  Lack true autonomy as steps are predefined, but they form a foundation for autonomous agents.\n\n  Often faster, cheaper, and more reliable than complex agent architectures, making them preferred for production.\n\n\n\nMeet the Agent\n\n  An agent differs from a fixed workflow or chatbot by deciding what to do next. It evaluates situations, chooses appropriate tools, and adapts if initial approaches fail. Agents operate on the OODA (Observe -> Orient -> Decide -> Act) loop:\n\n  - Observe: Gather input (e.g., a question, document, or event).\n\n  - Orient: Analyze and identify relevant information.\n\n  - Decide: Select the next action (e.g., tool, prompt, or path).\n\n  - Act: Execute the chosen action, then re-enter the observation phase.\n\n  This decision loop provides agents with flexibility to retry, re-plan, and adapt where static workflows cannot.\n\n\n\nFrom One Agent to Many (Multi-Agent Systems)\n\n  For problems too complex for a single agent, multi-agent systems are employed. These systems involve multiple agents with diverse strengths working together. Coordination can be centralized, with a supervisor agent directing tasks, or decentralized, where agents exchange information as peers to solve the problem. Ready Tensor's Agentic Authoring Assistant (A3) is an example, leveraging multiple AI agents for efficient content creation.\n\n\n\nLooking Ahead\n\n  This introductory week establishes a high-level understanding: workflows are predictable pipelines, agents offer autonomy through planning, deciding, and acting, and multi-agent systems coordinate teams for complex tasks. Future lessons will delve into the core components of an agent, including LLMs, tools, memory, and planning.\n\n\n\nOriginal Source: https://app.readytensor.ai/publications/what-is-agentic-ai-aaidc-week1-lecture1-g8QivAEShqgw", "mimetype": "text/plain", "start_char_idx": 2189, "end_char_idx": 4268, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}}